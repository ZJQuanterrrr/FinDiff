{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bl6_81TE1Hqp",
        "outputId": "7f7a5dc4-8a9c-4f15-ac15-53c7467651d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: dython in /usr/local/lib/python3.11/dist-packages (0.7.9)\n",
            "Requirement already satisfied: icecream in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: sdv==1.4.0 in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: boto3<2,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (1.38.23)\n",
            "Requirement already satisfied: botocore<2,>=1.18 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (1.38.23)\n",
            "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (2.2.1)\n",
            "Requirement already satisfied: Faker<15,>=10 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (14.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (4.67.1)\n",
            "Requirement already satisfied: copulas<0.10,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (0.9.2)\n",
            "Requirement already satisfied: ctgan<0.8,>=0.7.4 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (0.7.5)\n",
            "Requirement already satisfied: deepecho<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (0.4.2)\n",
            "Requirement already satisfied: rdt<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (1.7.0)\n",
            "Requirement already satisfied: sdmetrics<0.12,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (0.11.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.23.3 in /usr/local/lib/python3.11/dist-packages (from sdv==1.4.0) (1.24.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.15.0->sdv==1.4.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.15.0->sdv==1.4.0) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2,>=1.18->sdv==1.4.0) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2,>=1.18->sdv==1.4.0) (2.4.0)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from copulas<0.10,>=0.9.0->sdv==1.4.0) (3.10.0)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas<0.10,>=0.9.0->sdv==1.4.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from ctgan<0.8,>=0.7.4->sdv==1.4.0) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.4.0) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv==1.4.0) (1.17.0)\n",
            "Requirement already satisfied: psutil<6,>=5.7 in /usr/local/lib/python3.11/dist-packages (from rdt<2,>=1.7.0->sdv==1.4.0) (5.9.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv==1.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv==1.4.0) (3.6.0)\n",
            "Requirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from sdmetrics<0.12,>=0.11.0->sdv==1.4.0) (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.12,>=0.11.0->sdv==1.4.0) (9.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from dython) (0.13.2)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from icecream) (0.4.6)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from icecream) (2.19.1)\n",
            "Requirement already satisfied: executing>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from icecream) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from icecream) (3.0.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.0.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (0.14.4)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "fatal: destination path 'tab-ddpm' already exists and is not an empty directory.\n",
            "/content/tab-ddpm\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install torch==2.0.1 pandas openpyxl toml dython icecream optuna sdv==1.4.0 category-encoders\n",
        "\n",
        "!git clone https://github.com/yandex-research/tab-ddpm.git\n",
        "%cd tab-ddpm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tomli_w\n",
        "!pip install catboost\n",
        "!pip install skorch\n",
        "!pip install tomli\n",
        "!pip install zero\n",
        "!pip install rtdl\n",
        "!pip install sdv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1uvwjyK6BpO",
        "outputId": "b406d548-5727-4652-8dd6-d76a0e201bdc",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tomli_w in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.24.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.24.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.15.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
            "Requirement already satisfied: zero in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy>=1.15.2 in /usr/local/lib/python3.11/dist-packages (from zero) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from zero) (1.15.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from zero) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.1 in /usr/local/lib/python3.11/dist-packages (from zero) (2.32.3)\n",
            "Requirement already satisfied: progressbar2>=3.38.0 in /usr/local/lib/python3.11/dist-packages (from zero) (4.5.0)\n",
            "Requirement already satisfied: tabulate>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from zero) (0.9.0)\n",
            "Requirement already satisfied: setuptools-scm>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from zero) (8.3.1)\n",
            "Requirement already satisfied: ply>=3.11 in /usr/local/lib/python3.11/dist-packages (from zero) (3.11)\n",
            "Requirement already satisfied: Click==7.0 in /usr/local/lib/python3.11/dist-packages (from zero) (7.0)\n",
            "Requirement already satisfied: quantiphy>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from zero) (2.20)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.11/dist-packages (from zero) (6.0.2)\n",
            "Requirement already satisfied: graphviz>=0.9 in /usr/local/lib/python3.11/dist-packages (from zero) (0.20.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->zero) (2.9.0.post0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2>=3.38.0->zero) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->zero) (1.17.0)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.11/dist-packages (from python-utils>=3.8.1->progressbar2>=3.38.0->zero) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.1->zero) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.1->zero) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.1->zero) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.1->zero) (2025.4.26)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from setuptools-scm>=3.1.0->zero) (75.2.0)\n",
            "Collecting rtdl\n",
            "  Using cached rtdl-0.0.13-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.11/dist-packages (from rtdl) (1.24.4)\n",
            "Collecting torch<2,>=1.7 (from rtdl)\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch<2,>=1.7->rtdl) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<2,>=1.7->rtdl) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch<2,>=1.7->rtdl) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch<2,>=1.7->rtdl) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<2,>=1.7->rtdl) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.7->rtdl) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.7->rtdl) (0.45.1)\n",
            "Using cached rtdl-0.0.13-py3-none-any.whl (23 kB)\n",
            "Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, rtdl\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.0.1\n",
            "\u001b[2K    Uninstalling torch-2.0.1:\n",
            "\u001b[2K      Successfully uninstalled torch-2.0.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [rtdl]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ctgan 0.7.5 requires torch>=2.0.0; python_version >= \"3.11\", but you have torch 1.13.1 which is incompatible.\n",
            "deepecho 0.4.2 requires torch>=2.0.0; python_version >= \"3.11\", but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 1.13.1 which is incompatible.\n",
            "accelerate 1.6.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.11.0 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed rtdl-0.0.13 torch-1.13.1\n",
            "Requirement already satisfied: sdv in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: boto3<2,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.38.22)\n",
            "Requirement already satisfied: botocore<2,>=1.18 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.38.22)\n",
            "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.1)\n",
            "Requirement already satisfied: Faker<15,>=10 in /usr/local/lib/python3.11/dist-packages (from sdv) (14.2.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\n",
            "Requirement already satisfied: copulas<0.10,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.9.2)\n",
            "Requirement already satisfied: ctgan<0.8,>=0.7.4 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.7.5)\n",
            "Requirement already satisfied: deepecho<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.4.2)\n",
            "Requirement already satisfied: rdt<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.7.0)\n",
            "Requirement already satisfied: sdmetrics<0.12,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.11.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.23.3 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.24.4)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.15.0->sdv) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.15.0->sdv) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2,>=1.18->sdv) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2,>=1.18->sdv) (2.4.0)\n",
            "Requirement already satisfied: matplotlib<4,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from copulas<0.10,>=0.9.0->sdv) (3.10.0)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas<0.10,>=0.9.0->sdv) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from ctgan<0.8,>=0.7.4->sdv) (1.6.1)\n",
            "Collecting torch>=2.0.0 (from ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.17.0)\n",
            "Requirement already satisfied: psutil<6,>=5.7 in /usr/local/lib/python3.11/dist-packages (from rdt<2,>=1.7.0->sdv) (5.9.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.1.3->ctgan<0.8,>=0.7.4->sdv) (3.6.0)\n",
            "Requirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from sdmetrics<0.12,>=0.11.0->sdv) (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.12,>=0.11.0->sdv) (9.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan<0.8,>=0.7.4->sdv) (3.0.2)\n",
            "Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m161.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m168.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 2.0.0\n",
            "\u001b[2K    Uninstalling triton-2.0.0:\n",
            "\u001b[2K      Successfully uninstalled triton-2.0.0\n",
            "\u001b[2K  Attempting uninstall: sympy\n",
            "\u001b[2K    Found existing installation: sympy 1.13.1\n",
            "\u001b[2K    Uninstalling sympy-1.13.1:\n",
            "\u001b[2K      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 1.13.1\n",
            "\u001b[2K    Uninstalling torch-1.13.1:\n",
            "\u001b[2K      Successfully uninstalled torch-1.13.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rtdl 0.0.13 requires torch<2,>=1.7, but you have torch 2.7.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/train.py\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import zero\n",
        "\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
        "\n",
        "from tab_ddpm import GaussianMultinomialDiffusion\n",
        "from utils_train import get_model, make_dataset, update_ema\n",
        "import lib\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, diffusion, train_iter, lr, weight_decay, steps, device=torch.device('cuda:1')):\n",
        "        self.diffusion = diffusion\n",
        "        self.ema_model = deepcopy(self.diffusion._denoise_fn)\n",
        "        for param in self.ema_model.parameters():\n",
        "            param.detach_()\n",
        "\n",
        "        self.train_iter = train_iter\n",
        "        self.steps = steps\n",
        "        self.init_lr = lr\n",
        "        self.optimizer = torch.optim.AdamW(self.diffusion.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        self.device = device\n",
        "        self.loss_history = pd.DataFrame(columns=['step', 'mloss', 'gloss', 'loss'])\n",
        "        self.log_every = 100\n",
        "        self.print_every = 500\n",
        "        self.ema_every = 1000\n",
        "\n",
        "    def _anneal_lr(self, step):\n",
        "        frac_done = step / self.steps\n",
        "        lr = self.init_lr * (1 - frac_done)\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr\n",
        "\n",
        "    def _run_step(self, x, out_dict):\n",
        "        x = x.to(self.device)\n",
        "        for k in out_dict:\n",
        "            out_dict[k] = out_dict[k].long().to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss_multi, loss_gauss = self.diffusion.mixed_loss(x, out_dict)\n",
        "        loss = loss_multi + loss_gauss\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss_multi, loss_gauss\n",
        "\n",
        "    def run_loop(self):\n",
        "        step = 0\n",
        "        curr_loss_multi = 0.0\n",
        "        curr_loss_gauss = 0.0\n",
        "\n",
        "        curr_count = 0\n",
        "        while step < self.steps:\n",
        "            x, out_dict = next(self.train_iter)\n",
        "            out_dict = {'y': out_dict}\n",
        "            batch_loss_multi, batch_loss_gauss = self._run_step(x, out_dict)\n",
        "\n",
        "            self._anneal_lr(step)\n",
        "\n",
        "            curr_count += len(x)\n",
        "            curr_loss_multi += batch_loss_multi.item() * len(x)\n",
        "            curr_loss_gauss += batch_loss_gauss.item() * len(x)\n",
        "\n",
        "            if (step + 1) % self.log_every == 0:\n",
        "                mloss = np.around(curr_loss_multi / curr_count, 4)\n",
        "                gloss = np.around(curr_loss_gauss / curr_count, 4)\n",
        "                if (step + 1) % self.print_every == 0:\n",
        "                    print(f'Step {(step + 1)}/{self.steps} MLoss: {mloss} GLoss: {gloss} Sum: {mloss + gloss}')\n",
        "                self.loss_history.loc[len(self.loss_history)] =[step + 1, mloss, gloss, mloss + gloss]\n",
        "                curr_count = 0\n",
        "                curr_loss_gauss = 0.0\n",
        "                curr_loss_multi = 0.0\n",
        "\n",
        "            update_ema(self.ema_model.parameters(), self.diffusion._denoise_fn.parameters())\n",
        "\n",
        "            step += 1\n",
        "\n",
        "def train(\n",
        "    parent_dir,\n",
        "    real_data_path = 'data/higgs-small',\n",
        "    steps = 1000,\n",
        "    lr = 0.002,\n",
        "    weight_decay = 1e-4,\n",
        "    batch_size = 1024,\n",
        "    model_type = 'mlp',\n",
        "    model_params = None,\n",
        "    num_timesteps = 1000,\n",
        "    gaussian_loss_type = 'mse',\n",
        "    scheduler = 'cosine',\n",
        "    T_dict = None,\n",
        "    num_numerical_features = 0,\n",
        "    device = torch.device('cuda:1'),\n",
        "    seed = 0,\n",
        "    change_val = False\n",
        "):\n",
        "    real_data_path = os.path.normpath(real_data_path)\n",
        "    parent_dir = os.path.normpath(parent_dir)\n",
        "\n",
        "    def improve_reproducibility(seed):\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    improve_reproducibility(seed)\n",
        "\n",
        "    T = lib.Transformations(**T_dict)\n",
        "\n",
        "    dataset = make_dataset(\n",
        "        real_data_path,\n",
        "        T,\n",
        "        num_classes=model_params['num_classes'],\n",
        "        is_y_cond=model_params['is_y_cond'],\n",
        "        change_val=change_val\n",
        "    )\n",
        "\n",
        "    K = np.array(dataset.get_category_sizes('train'))\n",
        "    if len(K) == 0 or T_dict['cat_encoding'] == 'one-hot':\n",
        "        K = np.array([0])\n",
        "    print(K)\n",
        "\n",
        "    num_numerical_features = dataset.X_num['train'].shape[1] if dataset.X_num is not None else 0\n",
        "    d_in = np.sum(K) + num_numerical_features\n",
        "    model_params['d_in'] = d_in\n",
        "    print(d_in)\n",
        "\n",
        "    print(model_params)\n",
        "    model = get_model(\n",
        "        model_type,\n",
        "        model_params,\n",
        "        num_numerical_features,\n",
        "        category_sizes=dataset.get_category_sizes('train')\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    # train_loader = lib.prepare_beton_loader(dataset, split='train', batch_size=batch_size)\n",
        "    train_loader = lib.prepare_fast_dataloader(dataset, split='train', batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    diffusion = GaussianMultinomialDiffusion(\n",
        "        num_classes=K,\n",
        "        num_numerical_features=num_numerical_features,\n",
        "        denoise_fn=model,\n",
        "        gaussian_loss_type=gaussian_loss_type,\n",
        "        num_timesteps=num_timesteps,\n",
        "        scheduler=scheduler,\n",
        "        device=device\n",
        "    )\n",
        "    diffusion.to(device)\n",
        "    diffusion.train()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        diffusion,\n",
        "        train_loader,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "        steps=steps,\n",
        "        device=device\n",
        "    )\n",
        "    trainer.run_loop()\n",
        "\n",
        "    trainer.loss_history.to_csv(os.path.join(parent_dir, 'loss.csv'), index=False)\n",
        "    torch.save(diffusion._denoise_fn.state_dict(), os.path.join(parent_dir, 'model.pt'))\n",
        "    torch.save(trainer.ema_model.state_dict(), os.path.join(parent_dir, 'model_ema.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atSF8BV1c5nU",
        "outputId": "db41a4a5-a989-4729-e4e7-1e3124bed171"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lib/util.py\n",
        "import argparse\n",
        "import atexit\n",
        "import enum\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "from copy import deepcopy\n",
        "from dataclasses import asdict, fields, is_dataclass\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from typing import Any, Callable, List, Dict, Type, Optional, Tuple, TypeVar, Union, cast, get_args, get_origin\n",
        "\n",
        "import __main__\n",
        "import numpy as np\n",
        "import tomli\n",
        "import tomli_w\n",
        "import torch\n",
        "import zero\n",
        "\n",
        "from . import env\n",
        "\n",
        "RawConfig = Dict[str, Any]\n",
        "Report = Dict[str, Any]\n",
        "T = TypeVar('T')\n",
        "\n",
        "\n",
        "class Part(enum.Enum):\n",
        "    TRAIN = 'train'\n",
        "    VAL = 'val'\n",
        "    TEST = 'test'\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class TaskType(enum.Enum):\n",
        "    BINCLASS = 'binclass'\n",
        "    MULTICLASS = 'multiclass'\n",
        "    REGRESSION = 'regression'\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self.start_time = None\n",
        "        self.duration = 0\n",
        "\n",
        "    def run(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        if self.start_time is not None:\n",
        "            self.duration = time.time() - self.start_time\n",
        "            self.start_time = None\n",
        "        return self.duration\n",
        "\n",
        "    def get_duration(self):\n",
        "        return self.duration\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.duration:.2f} seconds\"\n",
        "\n",
        "    @classmethod\n",
        "    def launch(cls) -> 'Timer':\n",
        "        timer = cls()\n",
        "        timer.run()\n",
        "        return timer\n",
        "\n",
        "\n",
        "def update_training_log(training_log, data, metrics):\n",
        "    def _update(log_part, data_part):\n",
        "        for k, v in data_part.items():\n",
        "            if isinstance(v, dict):\n",
        "                _update(log_part.setdefault(k, {}), v)\n",
        "            elif isinstance(v, list):\n",
        "                log_part.setdefault(k, []).extend(v)\n",
        "            else:\n",
        "                log_part.setdefault(k, []).append(v)\n",
        "\n",
        "    _update(training_log, data)\n",
        "    transposed_metrics = {}\n",
        "    for part, part_metrics in metrics.items():\n",
        "        for metric_name, value in part_metrics.items():\n",
        "            transposed_metrics.setdefault(metric_name, {})[part] = value\n",
        "    _update(training_log, transposed_metrics)\n",
        "\n",
        "\n",
        "def raise_unknown(unknown_what: str, unknown_value: Any):\n",
        "    raise ValueError(f'Unknown {unknown_what}: {unknown_value}')\n",
        "\n",
        "\n",
        "def _replace(data, condition, value):\n",
        "    def do(x):\n",
        "        if isinstance(x, dict):\n",
        "            return {k: do(v) for k, v in x.items()}\n",
        "        elif isinstance(x, list):\n",
        "            return [do(y) for y in x]\n",
        "        else:\n",
        "            return value if condition(x) else x\n",
        "\n",
        "    return do(data)\n",
        "\n",
        "\n",
        "_CONFIG_NONE = '__none__'\n",
        "\n",
        "\n",
        "def unpack_config(config: RawConfig) -> RawConfig:\n",
        "    config = cast(RawConfig, _replace(config, lambda x: x == _CONFIG_NONE, None))\n",
        "    return config\n",
        "\n",
        "\n",
        "def pack_config(config: RawConfig) -> RawConfig:\n",
        "    config = cast(RawConfig, _replace(config, lambda x: x is None, _CONFIG_NONE))\n",
        "    return config\n",
        "\n",
        "\n",
        "def load_config(path: Union[Path, str]) -> Any:\n",
        "    with open(path, 'rb') as f:\n",
        "        return unpack_config(tomli.load(f))\n",
        "\n",
        "\n",
        "def dump_config(config: Any, path: Union[Path, str]) -> None:\n",
        "    with open(path, 'wb') as f:\n",
        "        tomli_w.dump(pack_config(config), f)\n",
        "    # check that there are no bugs in all these \"pack/unpack\" things\n",
        "    assert config == load_config(path)\n",
        "\n",
        "\n",
        "def load_json(path: Union[Path, str], **kwargs) -> Any:\n",
        "    return json.loads(Path(path).read_text(), **kwargs)\n",
        "\n",
        "\n",
        "def dump_json(x: Any, path: Union[Path, str], **kwargs) -> None:\n",
        "    kwargs.setdefault('indent', 4)\n",
        "    Path(path).write_text(json.dumps(x, **kwargs) + '\\n')\n",
        "\n",
        "\n",
        "def load_pickle(path: Union[Path, str], **kwargs) -> Any:\n",
        "    return pickle.loads(Path(path).read_bytes(), **kwargs)\n",
        "\n",
        "\n",
        "def dump_pickle(x: Any, path: Union[Path, str], **kwargs) -> None:\n",
        "    Path(path).write_bytes(pickle.dumps(x, **kwargs))\n",
        "\n",
        "\n",
        "def load(path: Union[Path, str], **kwargs) -> Any:\n",
        "    return globals()[f'load_{Path(path).suffix[1:]}'](Path(path), **kwargs)\n",
        "\n",
        "\n",
        "def dump(x: Any, path: Union[Path, str], **kwargs) -> Any:\n",
        "    return globals()[f'dump_{Path(path).suffix[1:]}'](x, Path(path), **kwargs)\n",
        "\n",
        "\n",
        "def _get_output_item_path(\n",
        "    path: Union[str, Path], filename: str, must_exist: bool\n",
        ") -> Path:\n",
        "    path = env.get_path(path)\n",
        "    if path.suffix == '.toml':\n",
        "        path = path.with_suffix('')\n",
        "    if path.is_dir():\n",
        "        path = path / filename\n",
        "    else:\n",
        "        assert path.name == filename\n",
        "    assert path.parent.exists()\n",
        "    if must_exist:\n",
        "        assert path.exists()\n",
        "    return path\n",
        "\n",
        "\n",
        "def load_report(path: Path) -> Report:\n",
        "    return load_json(_get_output_item_path(path, 'report.json', True))\n",
        "\n",
        "\n",
        "def dump_report(report: dict, path: Path) -> None:\n",
        "    dump_json(report, _get_output_item_path(path, 'report.json', False))\n",
        "\n",
        "\n",
        "def load_predictions(path: Path) -> Dict[str, np.ndarray]:\n",
        "    with np.load(_get_output_item_path(path, 'predictions.npz', True)) as predictions:\n",
        "        return {x: predictions[x] for x in predictions}\n",
        "\n",
        "\n",
        "def dump_predictions(predictions: Dict[str, np.ndarray], path: Path) -> None:\n",
        "    np.savez(_get_output_item_path(path, 'predictions.npz', False), **predictions)\n",
        "\n",
        "\n",
        "def dump_metrics(metrics: Dict[str, Any], path: Path) -> None:\n",
        "    dump_json(metrics, _get_output_item_path(path, 'metrics.json', False))\n",
        "\n",
        "\n",
        "def load_checkpoint(path: Path, *args, **kwargs) -> Dict[str, np.ndarray]:\n",
        "    return torch.load(\n",
        "        _get_output_item_path(path, 'checkpoint.pt', True), *args, **kwargs\n",
        "    )\n",
        "\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    if torch.cuda.is_available():\n",
        "        assert os.environ.get('CUDA_VISIBLE_DEVICES') is not None\n",
        "        return torch.device('cuda:0')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def _print_sep(c, size=100):\n",
        "    print(c * size)\n",
        "\n",
        "\n",
        "def start(\n",
        "    config_cls: Type[T] = RawConfig,\n",
        "    argv: Optional[List[str]] = None,\n",
        "    patch_raw_config: Optional[Callable[[RawConfig], None]] = None,\n",
        ") -> Tuple[T, Path, Report]:  # config  # output dir  # report\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('config', metavar='FILE')\n",
        "    parser.add_argument('--force', action='store_true')\n",
        "    parser.add_argument('--continue', action='store_true', dest='continue_')\n",
        "    if argv is None:\n",
        "        program = __main__.__file__\n",
        "        args = parser.parse_args()\n",
        "    else:\n",
        "        program = argv[0]\n",
        "        try:\n",
        "            args = parser.parse_args(argv[1:])\n",
        "        except Exception:\n",
        "            print(\n",
        "                'Failed to parse `argv`.'\n",
        "                ' Remember that the first item of `argv` must be the path (relative to'\n",
        "                ' the project root) to the script/notebook.'\n",
        "            )\n",
        "            raise\n",
        "    args = parser.parse_args(argv)\n",
        "\n",
        "    snapshot_dir = os.environ.get('SNAPSHOT_PATH')\n",
        "    if snapshot_dir and Path(snapshot_dir).joinpath('CHECKPOINTS_RESTORED').exists():\n",
        "        assert args.continue_\n",
        "\n",
        "    config_path = env.get_path(args.config)\n",
        "    output_dir = config_path.with_suffix('')\n",
        "    _print_sep('=')\n",
        "    print(f'[output] {output_dir}')\n",
        "    _print_sep('=')\n",
        "\n",
        "    assert config_path.exists()\n",
        "    raw_config = load_config(config_path)\n",
        "    if patch_raw_config is not None:\n",
        "        patch_raw_config(raw_config)\n",
        "    if is_dataclass(config_cls):\n",
        "        config = from_dict(config_cls, raw_config)\n",
        "        full_raw_config = asdict(config)\n",
        "    else:\n",
        "        assert config_cls is dict\n",
        "        full_raw_config = config = raw_config\n",
        "    full_raw_config = asdict(config)\n",
        "\n",
        "    if output_dir.exists():\n",
        "        if args.force:\n",
        "            print('Removing the existing output and creating a new one...')\n",
        "            shutil.rmtree(output_dir)\n",
        "            output_dir.mkdir()\n",
        "        elif not args.continue_:\n",
        "            backup_output(output_dir)\n",
        "            print('The output directory already exists. Done!\\n')\n",
        "            sys.exit()\n",
        "        elif output_dir.joinpath('DONE').exists():\n",
        "            backup_output(output_dir)\n",
        "            print('The \"DONE\" file already exists. Done!')\n",
        "            sys.exit()\n",
        "        else:\n",
        "            print('Continuing with the existing output...')\n",
        "    else:\n",
        "        print('Creating the output...')\n",
        "        output_dir.mkdir()\n",
        "\n",
        "    report = {\n",
        "        'program': str(env.get_relative_path(program)),\n",
        "        'environment': {},\n",
        "        'config': full_raw_config,\n",
        "    }\n",
        "    if torch.cuda.is_available():  # type: ignore[code]\n",
        "        report['environment'].update(\n",
        "            {\n",
        "                'CUDA_VISIBLE_DEVICES': os.environ.get('CUDA_VISIBLE_DEVICES'),\n",
        "                'gpus': zero.hardware.get_gpus_info(),\n",
        "                'torch.version.cuda': torch.version.cuda,\n",
        "                'torch.backends.cudnn.version()': torch.backends.cudnn.version(),  # type: ignore[code]\n",
        "                'torch.cuda.nccl.version()': torch.cuda.nccl.version(),  # type: ignore[code]\n",
        "            }\n",
        "        )\n",
        "    dump_report(report, output_dir)\n",
        "    dump_json(raw_config, output_dir / 'raw_config.json')\n",
        "    _print_sep('-')\n",
        "    pprint(full_raw_config, width=100)\n",
        "    _print_sep('-')\n",
        "    return cast(config_cls, config), output_dir, report\n",
        "\n",
        "\n",
        "_LAST_SNAPSHOT_TIME = None\n",
        "\n",
        "\n",
        "def backup_output(output_dir: Path) -> None:\n",
        "    backup_dir = os.environ.get('TMP_OUTPUT_PATH')\n",
        "    snapshot_dir = os.environ.get('SNAPSHOT_PATH')\n",
        "    if backup_dir is None:\n",
        "        assert snapshot_dir is None\n",
        "        return\n",
        "    assert snapshot_dir is not None\n",
        "\n",
        "    try:\n",
        "        relative_output_dir = output_dir.relative_to(env.PROJ)\n",
        "    except ValueError:\n",
        "        return\n",
        "\n",
        "    for dir_ in [backup_dir, snapshot_dir]:\n",
        "        new_output_dir = dir_ / relative_output_dir\n",
        "        prev_backup_output_dir = new_output_dir.with_name(new_output_dir.name + '_prev')\n",
        "        new_output_dir.parent.mkdir(exist_ok=True, parents=True)\n",
        "        if new_output_dir.exists():\n",
        "            new_output_dir.rename(prev_backup_output_dir)\n",
        "        shutil.copytree(output_dir, new_output_dir)\n",
        "        # the case for evaluate.py which automatically creates configs\n",
        "        if output_dir.with_suffix('.toml').exists():\n",
        "            shutil.copyfile(\n",
        "                output_dir.with_suffix('.toml'), new_output_dir.with_suffix('.toml')\n",
        "            )\n",
        "        if prev_backup_output_dir.exists():\n",
        "            shutil.rmtree(prev_backup_output_dir)\n",
        "\n",
        "    global _LAST_SNAPSHOT_TIME\n",
        "    if _LAST_SNAPSHOT_TIME is None or time.time() - _LAST_SNAPSHOT_TIME > 10 * 60:\n",
        "        import nirvana_dl.snapshot  # type: ignore[code]\n",
        "\n",
        "        nirvana_dl.snapshot.dump_snapshot()\n",
        "        _LAST_SNAPSHOT_TIME = time.time()\n",
        "        print('The snapshot was saved!')\n",
        "\n",
        "\n",
        "def _get_scores(metrics: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, float]]:\n",
        "    return (\n",
        "        {k: v['score'] for k, v in metrics.items()}\n",
        "        if 'score' in next(iter(metrics.values()))\n",
        "        else None\n",
        "    )\n",
        "\n",
        "\n",
        "def format_scores(metrics: Dict[str, Dict[str, Any]]) -> str:\n",
        "    return ' '.join(\n",
        "        f\"[{x}] {metrics[x]['score']:.3f}\"\n",
        "        for x in ['test', 'val', 'train']\n",
        "        if x in metrics\n",
        "    )\n",
        "\n",
        "\n",
        "def finish(output_dir: Path, report: dict) -> None:\n",
        "    print()\n",
        "    _print_sep('=')\n",
        "\n",
        "    metrics = report.get('metrics')\n",
        "    if metrics is not None:\n",
        "        scores = _get_scores(metrics)\n",
        "        if scores is not None:\n",
        "            dump_json(scores, output_dir / 'scores.json')\n",
        "            print(format_scores(metrics))\n",
        "            _print_sep('-')\n",
        "\n",
        "    dump_report(report, output_dir)\n",
        "    json_output_path = os.environ.get('JSON_OUTPUT_FILE')\n",
        "    if json_output_path:\n",
        "        try:\n",
        "            key = str(output_dir.relative_to(env.PROJ))\n",
        "        except ValueError:\n",
        "            pass\n",
        "        else:\n",
        "            json_output_path = Path(json_output_path)\n",
        "            try:\n",
        "                json_data = json.loads(json_output_path.read_text())\n",
        "            except (FileNotFoundError, json.decoder.JSONDecodeError):\n",
        "                json_data = {}\n",
        "            json_data[key] = load_json(output_dir / 'report.json')\n",
        "            json_output_path.write_text(json.dumps(json_data, indent=4))\n",
        "        shutil.copyfile(\n",
        "            json_output_path,\n",
        "            os.path.join(os.environ['SNAPSHOT_PATH'], 'json_output.json'),\n",
        "        )\n",
        "\n",
        "    output_dir.joinpath('DONE').touch()\n",
        "    backup_output(output_dir)\n",
        "    print(f'Done! | {report.get(\"time\")} | {output_dir}')\n",
        "    _print_sep('=')\n",
        "    print()\n",
        "\n",
        "\n",
        "def from_dict(datacls: Type[T], data: dict) -> T:\n",
        "    assert is_dataclass(datacls)\n",
        "    data = deepcopy(data)\n",
        "    for field in fields(datacls):\n",
        "        if field.name not in data:\n",
        "            continue\n",
        "        if is_dataclass(field.type):\n",
        "            data[field.name] = from_dict(field.type, data[field.name])\n",
        "        elif (\n",
        "            get_origin(field.type) is Union\n",
        "            and len(get_args(field.type)) == 2\n",
        "            and get_args(field.type)[1] is type(None)\n",
        "            and is_dataclass(get_args(field.type)[0])\n",
        "        ):\n",
        "            if data[field.name] is not None:\n",
        "                data[field.name] = from_dict(get_args(field.type)[0], data[field.name])\n",
        "    return datacls(**data)\n",
        "\n",
        "\n",
        "def replace_factor_with_value(\n",
        "    config: RawConfig,\n",
        "    key: str,\n",
        "    reference_value: int,\n",
        "    bounds: Tuple[float, float],\n",
        ") -> None:\n",
        "    factor_key = key + '_factor'\n",
        "    if factor_key not in config:\n",
        "        assert key in config\n",
        "    else:\n",
        "        assert key not in config\n",
        "        factor = config.pop(factor_key)\n",
        "        assert bounds[0] <= factor <= bounds[1]\n",
        "        config[key] = int(factor * reference_value)\n",
        "\n",
        "\n",
        "def get_temporary_copy(path: Union[str, Path]) -> Path:\n",
        "    path = env.get_path(path)\n",
        "    assert not path.is_dir() and not path.is_symlink()\n",
        "    tmp_path = path.with_name(\n",
        "        path.stem + '___' + str(uuid.uuid4()).replace('-', '') + path.suffix\n",
        "    )\n",
        "    shutil.copyfile(path, tmp_path)\n",
        "    atexit.register(lambda: tmp_path.unlink())\n",
        "    return tmp_path\n",
        "\n",
        "\n",
        "def get_python():\n",
        "    python = Path('python3.9')\n",
        "    return str(python) if python.exists() else 'python'\n",
        "\n",
        "def get_catboost_config(real_data_path, is_cv=False):\n",
        "    ds_name = Path(real_data_path).name\n",
        "    C = load_json(f'tuned_models/catboost/{ds_name}_cv.json')\n",
        "    return C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJdF2SaAeFeg",
        "outputId": "c57221dd-bae0-4e31-bbad-116eeed42e43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lib/util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/pipeline.py\n",
        "import tomli\n",
        "import shutil\n",
        "import os\n",
        "import argparse\n",
        "from train import train\n",
        "from sample import sample\n",
        "from eval_catboost import train_catboost\n",
        "from eval_mlp import train_mlp\n",
        "from eval_simple import train_simple\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zero\n",
        "import lib\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
        "from lib.util import Timer\n",
        "\n",
        "\n",
        "def load_config(path) :\n",
        "    with open(path, 'rb') as f:\n",
        "        return tomli.load(f)\n",
        "\n",
        "def save_file(parent_dir, config_path):\n",
        "    try:\n",
        "        dst = os.path.join(parent_dir)\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.copyfile(os.path.abspath(config_path), dst)\n",
        "    except shutil.SameFileError:\n",
        "        pass\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--config', metavar='FILE')\n",
        "    parser.add_argument('--train', action='store_true', default=False)\n",
        "    parser.add_argument('--sample', action='store_true',  default=False)\n",
        "    parser.add_argument('--eval', action='store_true',  default=False)\n",
        "    parser.add_argument('--change_val', action='store_true',  default=False)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    raw_config = lib.load_config(args.config)\n",
        "    if 'device' in raw_config:\n",
        "        device = torch.device(raw_config['device'])\n",
        "    else:\n",
        "        device = torch.device('cuda:1')\n",
        "\n",
        "    timer = Timer()\n",
        "    timer.run()\n",
        "    save_file(os.path.join(raw_config['parent_dir'], 'config.toml'), args.config)\n",
        "\n",
        "    if args.train:\n",
        "        train(\n",
        "            **raw_config['train']['main'],\n",
        "            **raw_config['diffusion_params'],\n",
        "            parent_dir=raw_config['parent_dir'],\n",
        "            real_data_path=raw_config['real_data_path'],\n",
        "            model_type=raw_config['model_type'],\n",
        "            model_params=raw_config['model_params'],\n",
        "            T_dict=raw_config['train']['T'],\n",
        "            num_numerical_features=raw_config['num_numerical_features'],\n",
        "            device=device,\n",
        "            change_val=args.change_val\n",
        "        )\n",
        "    if args.sample:\n",
        "        sample(\n",
        "            num_samples=raw_config['sample']['num_samples'],\n",
        "            batch_size=raw_config['sample']['batch_size'],\n",
        "            disbalance=raw_config['sample'].get('disbalance', None),\n",
        "            **raw_config['diffusion_params'],\n",
        "            parent_dir=raw_config['parent_dir'],\n",
        "            real_data_path=raw_config['real_data_path'],\n",
        "            model_path=os.path.join(raw_config['parent_dir'], 'model.pt'),\n",
        "            model_type=raw_config['model_type'],\n",
        "            model_params=raw_config['model_params'],\n",
        "            T_dict=raw_config['train']['T'],\n",
        "            num_numerical_features=raw_config['num_numerical_features'],\n",
        "            device=device,\n",
        "            seed=raw_config['sample'].get('seed', 0),\n",
        "            change_val=args.change_val\n",
        "        )\n",
        "\n",
        "    save_file(os.path.join(raw_config['parent_dir'], 'info.json'), os.path.join(raw_config['real_data_path'], 'info.json'))\n",
        "    if args.eval:\n",
        "        if raw_config['eval']['type']['eval_model'] == 'catboost':\n",
        "            train_catboost(\n",
        "                parent_dir=raw_config['parent_dir'],\n",
        "                real_data_path=raw_config['real_data_path'],\n",
        "                eval_type=raw_config['eval']['type']['eval_type'],\n",
        "                T_dict=raw_config['eval']['T'],\n",
        "                seed=raw_config['seed'],\n",
        "                change_val=args.change_val\n",
        "            )\n",
        "        elif raw_config['eval']['type']['eval_model'] == 'mlp':\n",
        "            train_mlp(\n",
        "                parent_dir=raw_config['parent_dir'],\n",
        "                real_data_path=raw_config['real_data_path'],\n",
        "                eval_type=raw_config['eval']['type']['eval_type'],\n",
        "                T_dict=raw_config['eval']['T'],\n",
        "                seed=raw_config['seed'],\n",
        "                change_val=args.change_val,\n",
        "                device=device\n",
        "            )\n",
        "        elif raw_config['eval']['type']['eval_model'] == 'simple':\n",
        "            train_simple(\n",
        "                parent_dir=raw_config['parent_dir'],\n",
        "                real_data_path=raw_config['real_data_path'],\n",
        "                eval_type=raw_config['eval']['type']['eval_type'],\n",
        "                T_dict=raw_config['eval']['T'],\n",
        "                seed=raw_config['seed'],\n",
        "                change_val=args.change_val\n",
        "            )\n",
        "\n",
        "    print(f'Elapsed time: {str(timer)}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz94g-pYhahv",
        "outputId": "fce325ee-1b48-4c2e-bbc6-c25e8d4c5027"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/pipeline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lib/data.py\n",
        "import hashlib\n",
        "from collections import Counter\n",
        "from copy import deepcopy\n",
        "from dataclasses import astuple, dataclass, replace\n",
        "from importlib.resources import path\n",
        "from pathlib import Path\n",
        "from typing import Any, Literal, Optional, Union, cast, Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import os\n",
        "from category_encoders import LeaveOneOutEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "from . import env, util\n",
        "from .metrics import calculate_metrics as calculate_metrics_\n",
        "from .util import TaskType, load_json\n",
        "\n",
        "ArrayDict = Dict[str, np.ndarray]\n",
        "TensorDict = Dict[str, torch.Tensor]\n",
        "\n",
        "\n",
        "CAT_MISSING_VALUE = '__nan__'\n",
        "CAT_RARE_VALUE = '__rare__'\n",
        "Normalization = Literal['standard', 'quantile', 'minmax']\n",
        "NumNanPolicy = Literal['drop-rows', 'mean']\n",
        "CatNanPolicy = Literal['most_frequent']\n",
        "CatEncoding = Literal['one-hot', 'counter']\n",
        "YPolicy = Literal['default']\n",
        "\n",
        "\n",
        "class StandardScaler1d(StandardScaler):\n",
        "    def partial_fit(self, X, *args, **kwargs):\n",
        "        assert X.ndim == 1\n",
        "        return super().partial_fit(X[:, None], *args, **kwargs)\n",
        "\n",
        "    def transform(self, X, *args, **kwargs):\n",
        "        assert X.ndim == 1\n",
        "        return super().transform(X[:, None], *args, **kwargs).squeeze(1)\n",
        "\n",
        "    def inverse_transform(self, X, *args, **kwargs):\n",
        "        assert X.ndim == 1\n",
        "        return super().inverse_transform(X[:, None], *args, **kwargs).squeeze(1)\n",
        "\n",
        "\n",
        "def get_category_sizes(X: Union[torch.Tensor, np.ndarray]) -> List[int]:\n",
        "    XT = X.T.cpu().tolist() if isinstance(X, torch.Tensor) else X.T.tolist()\n",
        "    return [len(set(x)) for x in XT]\n",
        "\n",
        "\n",
        "@dataclass(frozen=False)\n",
        "class Dataset:\n",
        "    X_num: Optional[ArrayDict]\n",
        "    X_cat: Optional[ArrayDict]\n",
        "    y: ArrayDict\n",
        "    y_info: Dict[str, Any]\n",
        "    task_type: TaskType\n",
        "    n_classes: Optional[int]\n",
        "\n",
        "    @classmethod\n",
        "    def from_dir(cls, dir_: Union[Path, str]) -> 'Dataset':\n",
        "        dir_ = Path(dir_)\n",
        "        splits = [k for k in ['train', 'val', 'test'] if dir_.joinpath(f'y_{k}.npy').exists()]\n",
        "\n",
        "        def load(item) -> ArrayDict:\n",
        "            return {\n",
        "                x: cast(np.ndarray, np.load(dir_ / f'{item}_{x}.npy', allow_pickle=True))  # type: ignore[code]\n",
        "                for x in splits\n",
        "            }\n",
        "\n",
        "        if Path(dir_ / 'info.json').exists():\n",
        "            info = util.load_json(dir_ / 'info.json')\n",
        "        else:\n",
        "            info = None\n",
        "        return Dataset(\n",
        "            load('X_num') if dir_.joinpath('X_num_train.npy').exists() else None,\n",
        "            load('X_cat') if dir_.joinpath('X_cat_train.npy').exists() else None,\n",
        "            load('y'),\n",
        "            {},\n",
        "            TaskType(info['task_type']),\n",
        "            info.get('n_classes'),\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def is_binclass(self) -> bool:\n",
        "        return self.task_type == TaskType.BINCLASS\n",
        "\n",
        "    @property\n",
        "    def is_multiclass(self) -> bool:\n",
        "        return self.task_type == TaskType.MULTICLASS\n",
        "\n",
        "    @property\n",
        "    def is_regression(self) -> bool:\n",
        "        return self.task_type == TaskType.REGRESSION\n",
        "\n",
        "    @property\n",
        "    def n_num_features(self) -> int:\n",
        "        return 0 if self.X_num is None else self.X_num['train'].shape[1]\n",
        "\n",
        "    @property\n",
        "    def n_cat_features(self) -> int:\n",
        "        return 0 if self.X_cat is None else self.X_cat['train'].shape[1]\n",
        "\n",
        "    @property\n",
        "    def n_features(self) -> int:\n",
        "        return self.n_num_features + self.n_cat_features\n",
        "\n",
        "    def size(self, part: Optional[str]) -> int:\n",
        "        return sum(map(len, self.y.values())) if part is None else len(self.y[part])\n",
        "\n",
        "    @property\n",
        "    def nn_output_dim(self) -> int:\n",
        "        if self.is_multiclass:\n",
        "            assert self.n_classes is not None\n",
        "            return self.n_classes\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def get_category_sizes(self, part: str) -> List[int]:\n",
        "        return [] if self.X_cat is None else get_category_sizes(self.X_cat[part])\n",
        "\n",
        "    def calculate_metrics(\n",
        "        self,\n",
        "        predictions: Dict[str, np.ndarray],\n",
        "        prediction_type: Optional[str],\n",
        "    ) -> Dict[str, Any]:\n",
        "        metrics = {\n",
        "            x: calculate_metrics_(\n",
        "                self.y[x], predictions[x], self.task_type, prediction_type, self.y_info\n",
        "            )\n",
        "            for x in predictions\n",
        "        }\n",
        "        if self.task_type == TaskType.REGRESSION:\n",
        "            score_key = 'rmse'\n",
        "            score_sign = -1\n",
        "        else:\n",
        "            score_key = 'accuracy'\n",
        "            score_sign = 1\n",
        "        for part_metrics in metrics.values():\n",
        "            part_metrics['score'] = score_sign * part_metrics[score_key]\n",
        "        return metrics\n",
        "\n",
        "def change_val(dataset: Dataset, val_size: float = 0.2):\n",
        "    # should be done before transformations\n",
        "\n",
        "    y = np.concatenate([dataset.y['train'], dataset.y['val']], axis=0)\n",
        "\n",
        "    ixs = np.arange(y.shape[0])\n",
        "    if dataset.is_regression:\n",
        "        train_ixs, val_ixs = train_test_split(ixs, test_size=val_size, random_state=777)\n",
        "    else:\n",
        "        train_ixs, val_ixs = train_test_split(ixs, test_size=val_size, random_state=777, stratify=y)\n",
        "\n",
        "    dataset.y['train'] = y[train_ixs]\n",
        "    dataset.y['val'] = y[val_ixs]\n",
        "\n",
        "    if dataset.X_num is not None:\n",
        "        X_num = np.concatenate([dataset.X_num['train'], dataset.X_num['val']], axis=0)\n",
        "        dataset.X_num['train'] = X_num[train_ixs]\n",
        "        dataset.X_num['val'] = X_num[val_ixs]\n",
        "\n",
        "    if dataset.X_cat is not None:\n",
        "        X_cat = np.concatenate([dataset.X_cat['train'], dataset.X_cat['val']], axis=0)\n",
        "        dataset.X_cat['train'] = X_cat[train_ixs]\n",
        "        dataset.X_cat['val'] = X_cat[val_ixs]\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def num_process_nans(dataset: Dataset, policy: Optional[NumNanPolicy]) -> Dataset:\n",
        "    assert dataset.X_num is not None\n",
        "    nan_masks = {k: np.isnan(v) for k, v in dataset.X_num.items()}\n",
        "    if not any(x.any() for x in nan_masks.values()):  # type: ignore[code]\n",
        "        assert policy is None\n",
        "        return dataset\n",
        "\n",
        "    assert policy is not None\n",
        "    if policy == 'drop-rows':\n",
        "        valid_masks = {k: ~v.any(1) for k, v in nan_masks.items()}\n",
        "        assert valid_masks[\n",
        "            'test'\n",
        "        ].all(), 'Cannot drop test rows, since this will affect the final metrics.'\n",
        "        new_data = {}\n",
        "        for data_name in ['X_num', 'X_cat', 'y']:\n",
        "            data_dict = getattr(dataset, data_name)\n",
        "            if data_dict is not None:\n",
        "                new_data[data_name] = {\n",
        "                    k: v[valid_masks[k]] for k, v in data_dict.items()\n",
        "                }\n",
        "        dataset = replace(dataset, **new_data)\n",
        "    elif policy == 'mean':\n",
        "        new_values = np.nanmean(dataset.X_num['train'], axis=0)\n",
        "        X_num = deepcopy(dataset.X_num)\n",
        "        for k, v in X_num.items():\n",
        "            num_nan_indices = np.where(nan_masks[k])\n",
        "            v[num_nan_indices] = np.take(new_values, num_nan_indices[1])\n",
        "        dataset = replace(dataset, X_num=X_num)\n",
        "    else:\n",
        "        assert util.raise_unknown('policy', policy)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Inspired by: https://github.com/yandex-research/rtdl/blob/a4c93a32b334ef55d2a0559a4407c8306ffeeaee/lib/data.py#L20\n",
        "def normalize(\n",
        "    X: ArrayDict, normalization: Normalization, seed: Optional[int], return_normalizer : bool = False\n",
        ") -> ArrayDict:\n",
        "    X_train = X['train']\n",
        "    if normalization == 'standard':\n",
        "        normalizer = sklearn.preprocessing.StandardScaler()\n",
        "    elif normalization == 'minmax':\n",
        "        normalizer = sklearn.preprocessing.MinMaxScaler()\n",
        "    elif normalization == 'quantile':\n",
        "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
        "            output_distribution='normal',\n",
        "            n_quantiles=max(min(X['train'].shape[0] // 30, 1000), 10),\n",
        "            subsample=1e9,\n",
        "            random_state=seed,\n",
        "        )\n",
        "        # noise = 1e-3\n",
        "        # if noise > 0:\n",
        "        #     assert seed is not None\n",
        "        #     stds = np.std(X_train, axis=0, keepdims=True)\n",
        "        #     noise_std = noise / np.maximum(stds, noise)  # type: ignore[code]\n",
        "        #     X_train = X_train + noise_std * np.random.default_rng(seed).standard_normal(\n",
        "        #         X_train.shape\n",
        "        #     )\n",
        "    else:\n",
        "        util.raise_unknown('normalization', normalization)\n",
        "    normalizer.fit(X_train)\n",
        "    if return_normalizer:\n",
        "        return {k: normalizer.transform(v) for k, v in X.items()}, normalizer\n",
        "    return {k: normalizer.transform(v) for k, v in X.items()}\n",
        "\n",
        "\n",
        "def cat_process_nans(X: ArrayDict, policy: Optional[CatNanPolicy]) -> ArrayDict:\n",
        "    assert X is not None\n",
        "    X = {k: v.astype(str) for k, v in X.items()}\n",
        "    nan_masks = {\n",
        "        k: np.equal(v, CAT_MISSING_VALUE) if isinstance(v, np.ndarray) else np.array([False])\n",
        "        for k, v in X.items()\n",
        "    }\n",
        "    if any(np.any(x) for x in nan_masks.values()):\n",
        "        if policy is None:\n",
        "            X_new = X\n",
        "        elif policy == 'most_frequent':\n",
        "            imputer = SimpleImputer(missing_values=CAT_MISSING_VALUE, strategy=policy)  # type: ignore[code]\n",
        "            imputer.fit(X['train'])\n",
        "            X_new = {k: cast(np.ndarray, imputer.transform(v)) for k, v in X.items()}\n",
        "        else:\n",
        "            util.raise_unknown('categorical NaN policy', policy)\n",
        "    else:\n",
        "        assert policy is None\n",
        "        X_new = X\n",
        "    return X_new\n",
        "\n",
        "\n",
        "def cat_drop_rare(X: ArrayDict, min_frequency: float) -> ArrayDict:\n",
        "    assert 0.0 < min_frequency < 1.0\n",
        "    min_count = round(len(X['train']) * min_frequency)\n",
        "    X_new = {x: [] for x in X}\n",
        "    for column_idx in range(X['train'].shape[1]):\n",
        "        counter = Counter(X['train'][:, column_idx].tolist())\n",
        "        popular_categories = {k for k, v in counter.items() if v >= min_count}\n",
        "        for part in X_new:\n",
        "            X_new[part].append(\n",
        "                [\n",
        "                    (x if x in popular_categories else CAT_RARE_VALUE)\n",
        "                    for x in X[part][:, column_idx].tolist()\n",
        "                ]\n",
        "            )\n",
        "    return {k: np.array(v).T for k, v in X_new.items()}\n",
        "\n",
        "\n",
        "def cat_encode(\n",
        "    X: ArrayDict,\n",
        "    encoding: Optional[CatEncoding],\n",
        "    y_train: Optional[np.ndarray],\n",
        "    seed: Optional[int],\n",
        "    return_encoder : bool = False\n",
        ") -> Tuple[ArrayDict, bool, Optional[Any]]:  # (X, is_converted_to_numerical)\n",
        "    if encoding != 'counter':\n",
        "        y_train = None\n",
        "\n",
        "    # Step 1. Map strings to 0-based ranges\n",
        "\n",
        "    if encoding is None:\n",
        "        unknown_value = np.iinfo('int64').max - 3\n",
        "        oe = sklearn.preprocessing.OrdinalEncoder(\n",
        "            handle_unknown='use_encoded_value',  # type: ignore[code]\n",
        "            unknown_value=unknown_value,  # type: ignore[code]\n",
        "            dtype='int64',  # type: ignore[code]\n",
        "        ).fit(X['train'])\n",
        "        encoder = make_pipeline(oe)\n",
        "        encoder.fit(X['train'])\n",
        "        X = {k: encoder.transform(v) for k, v in X.items()}\n",
        "        max_values = X['train'].max(axis=0)\n",
        "        for part in X.keys():\n",
        "            if part == 'train': continue\n",
        "            for column_idx in range(X[part].shape[1]):\n",
        "                X[part][X[part][:, column_idx] == unknown_value, column_idx] = (\n",
        "                    max_values[column_idx] + 1\n",
        "                )\n",
        "        if return_encoder:\n",
        "            return (X, False, encoder)\n",
        "        return (X, False)\n",
        "\n",
        "    # Step 2. Encode.\n",
        "\n",
        "    elif encoding == 'one-hot':\n",
        "        ohe = sklearn.preprocessing.OneHotEncoder(\n",
        "            handle_unknown='ignore', sparse=False, dtype=np.float32 # type: ignore[code]\n",
        "        )\n",
        "        encoder = make_pipeline(ohe)\n",
        "\n",
        "        # encoder.steps.append(('ohe', ohe))\n",
        "        encoder.fit(X['train'])\n",
        "        X = {k: encoder.transform(v) for k, v in X.items()}\n",
        "    elif encoding == 'counter':\n",
        "        assert y_train is not None\n",
        "        assert seed is not None\n",
        "        loe = LeaveOneOutEncoder(sigma=0.1, random_state=seed, return_df=False)\n",
        "        encoder.steps.append(('loe', loe))\n",
        "        encoder.fit(X['train'], y_train)\n",
        "        X = {k: encoder.transform(v).astype('float32') for k, v in X.items()}  # type: ignore[code]\n",
        "        if not isinstance(X['train'], pd.DataFrame):\n",
        "            X = {k: v.values for k, v in X.items()}  # type: ignore[code]\n",
        "    else:\n",
        "        util.raise_unknown('encoding', encoding)\n",
        "\n",
        "    if return_encoder:\n",
        "        return X, True, encoder # type: ignore[code]\n",
        "    return (X, True)\n",
        "\n",
        "\n",
        "def build_target(\n",
        "    y: ArrayDict, policy: Optional[YPolicy], task_type: TaskType\n",
        ") -> Tuple[ArrayDict, Dict[str, Any]]:\n",
        "    info: Dict[str, Any] = {'policy': policy}\n",
        "    if policy is None:\n",
        "        pass\n",
        "    elif policy == 'default':\n",
        "        if task_type == TaskType.REGRESSION:\n",
        "            mean, std = float(y['train'].mean()), float(y['train'].std())\n",
        "            y = {k: (v - mean) / std for k, v in y.items()}\n",
        "            info['mean'] = mean\n",
        "            info['std'] = std\n",
        "    else:\n",
        "        util.raise_unknown('policy', policy)\n",
        "    return y, info\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Transformations:\n",
        "    seed: int = 0\n",
        "    normalization: Optional[Normalization] = None\n",
        "    num_nan_policy: Optional[NumNanPolicy] = None\n",
        "    cat_nan_policy: Optional[CatNanPolicy] = None\n",
        "    cat_min_frequency: Optional[float] = None\n",
        "    cat_encoding: Optional[CatEncoding] = None\n",
        "    y_policy: Optional[YPolicy] = 'default'\n",
        "\n",
        "\n",
        "def transform_dataset(\n",
        "    dataset: Dataset,\n",
        "    transformations: Transformations,\n",
        "    cache_dir: Optional[Path],\n",
        "    return_transforms: bool = False\n",
        ") -> Dataset:\n",
        "    # WARNING: the order of transformations matters. Moreover, the current\n",
        "    # implementation is not ideal in that sense.\n",
        "    if cache_dir is not None:\n",
        "        transformations_md5 = hashlib.md5(\n",
        "            str(transformations).encode('utf-8')\n",
        "        ).hexdigest()\n",
        "        transformations_str = '__'.join(map(str, astuple(transformations)))\n",
        "        cache_path = (\n",
        "            cache_dir / f'cache__{transformations_str}__{transformations_md5}.pickle'\n",
        "        )\n",
        "        if cache_path.exists():\n",
        "            cache_transformations, value = util.load_pickle(cache_path)\n",
        "            if transformations == cache_transformations:\n",
        "                print(\n",
        "                    f\"Using cached features: {cache_dir.name + '/' + cache_path.name}\"\n",
        "                )\n",
        "                return value\n",
        "            else:\n",
        "                raise RuntimeError(f'Hash collision for {cache_path}')\n",
        "    else:\n",
        "        cache_path = None\n",
        "\n",
        "    if dataset.X_num is not None:\n",
        "        dataset = num_process_nans(dataset, transformations.num_nan_policy)\n",
        "\n",
        "    num_transform = None\n",
        "    cat_transform = None\n",
        "    X_num = dataset.X_num\n",
        "\n",
        "    if X_num is not None and transformations.normalization is not None:\n",
        "        X_num, num_transform = normalize(\n",
        "            X_num,\n",
        "            transformations.normalization,\n",
        "            transformations.seed,\n",
        "            return_normalizer=True\n",
        "        )\n",
        "        num_transform = num_transform\n",
        "\n",
        "    if dataset.X_cat is None:\n",
        "        assert transformations.cat_nan_policy is None\n",
        "        assert transformations.cat_min_frequency is None\n",
        "        # assert transformations.cat_encoding is None\n",
        "        X_cat = None\n",
        "    else:\n",
        "        X_cat = cat_process_nans(dataset.X_cat, transformations.cat_nan_policy)\n",
        "        if transformations.cat_min_frequency is not None:\n",
        "            X_cat = cat_drop_rare(X_cat, transformations.cat_min_frequency)\n",
        "        X_cat, is_num, cat_transform = cat_encode(\n",
        "            X_cat,\n",
        "            transformations.cat_encoding,\n",
        "            dataset.y['train'],\n",
        "            transformations.seed,\n",
        "            return_encoder=True\n",
        "        )\n",
        "        if is_num:\n",
        "            X_num = (\n",
        "                X_cat\n",
        "                if X_num is None\n",
        "                else {x: np.hstack([X_num[x], X_cat[x]]) for x in X_num}\n",
        "            )\n",
        "            X_cat = None\n",
        "\n",
        "    y, y_info = build_target(dataset.y, transformations.y_policy, dataset.task_type)\n",
        "\n",
        "    dataset = replace(dataset, X_num=X_num, X_cat=X_cat, y=y, y_info=y_info)\n",
        "    dataset.num_transform = num_transform\n",
        "    dataset.cat_transform = cat_transform\n",
        "\n",
        "    if cache_path is not None:\n",
        "        util.dump_pickle((transformations, dataset), cache_path)\n",
        "    # if return_transforms:\n",
        "        # return dataset, num_transform, cat_transform\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def build_dataset(\n",
        "    path: Union[str, Path],\n",
        "    transformations: Transformations,\n",
        "    cache: bool\n",
        ") -> Dataset:\n",
        "    path = Path(path)\n",
        "    dataset = Dataset.from_dir(path)\n",
        "    return transform_dataset(dataset, transformations, path if cache else None)\n",
        "\n",
        "\n",
        "def prepare_tensors(\n",
        "    dataset: Dataset, device: Union[str, torch.device]\n",
        ") -> Tuple[Optional[TensorDict], Optional[TensorDict], TensorDict]:\n",
        "    X_num, X_cat, Y = (\n",
        "        None if x is None else {k: torch.as_tensor(v) for k, v in x.items()}\n",
        "        for x in [dataset.X_num, dataset.X_cat, dataset.y]\n",
        "    )\n",
        "    if device.type != 'cpu':\n",
        "        X_num, X_cat, Y = (\n",
        "            None if x is None else {k: v.to(device) for k, v in x.items()}\n",
        "            for x in [X_num, X_cat, Y]\n",
        "        )\n",
        "    assert X_num is not None\n",
        "    assert Y is not None\n",
        "    if not dataset.is_multiclass:\n",
        "        Y = {k: v.float() for k, v in Y.items()}\n",
        "    return X_num, X_cat, Y\n",
        "\n",
        "###############\n",
        "## DataLoader##\n",
        "###############\n",
        "\n",
        "class TabDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, dataset : Dataset, split : Literal['train', 'val', 'test']\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.X_num = torch.from_numpy(dataset.X_num[split]) if dataset.X_num is not None else None\n",
        "        self.X_cat = torch.from_numpy(dataset.X_cat[split]) if dataset.X_cat is not None else None\n",
        "        self.y = torch.from_numpy(dataset.y[split])\n",
        "\n",
        "        assert self.y is not None\n",
        "        assert self.X_num is not None or self.X_cat is not None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_dict = {\n",
        "            'y': self.y[idx].long() if self.y is not None else None,\n",
        "        }\n",
        "\n",
        "        x = np.empty((0,))\n",
        "        if self.X_num is not None:\n",
        "            x = self.X_num[idx]\n",
        "        if self.X_cat is not None:\n",
        "            x = torch.cat([x, self.X_cat[idx]], dim=0)\n",
        "        return x.float(), out_dict\n",
        "\n",
        "def prepare_dataloader(\n",
        "    dataset : Dataset,\n",
        "    split : str,\n",
        "    batch_size: int,\n",
        "):\n",
        "\n",
        "    torch_dataset = TabDataset(dataset, split)\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(split == 'train'),\n",
        "        num_workers=1,\n",
        "    )\n",
        "    while True:\n",
        "        yield from loader\n",
        "\n",
        "def prepare_torch_dataloader(\n",
        "    dataset : Dataset,\n",
        "    split : str,\n",
        "    shuffle : bool,\n",
        "    batch_size: int,\n",
        ") -> torch.utils.data.DataLoader:\n",
        "\n",
        "    torch_dataset = TabDataset(dataset, split)\n",
        "    loader = torch.utils.data.DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=1)\n",
        "\n",
        "    return loader\n",
        "\n",
        "def dataset_from_csv(paths : Dict[str, str], cat_features, target, T):\n",
        "    assert 'train' in paths\n",
        "    y = {}\n",
        "    X_num = {}\n",
        "    X_cat = {} if len(cat_features) else None\n",
        "    for split in paths.keys():\n",
        "        df = pd.read_csv(paths[split])\n",
        "        y[split] = df[target].to_numpy().astype(float)\n",
        "        if X_cat is not None:\n",
        "            X_cat[split] = df[cat_features].to_numpy().astype(str)\n",
        "        X_num[split] = df.drop(cat_features + [target], axis=1).to_numpy().astype(float)\n",
        "\n",
        "    dataset = Dataset(X_num, X_cat, y, {}, None, len(np.unique(y['train'])))\n",
        "    return transform_dataset(dataset, T, None)\n",
        "\n",
        "class FastTensorDataLoader:\n",
        "    \"\"\"\n",
        "    A DataLoader-like object for a set of tensors that can be much faster than\n",
        "    TensorDataset + DataLoader because dataloader grabs individual indices of\n",
        "    the dataset and calls cat (slow).\n",
        "    Source: https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6\n",
        "    \"\"\"\n",
        "    def __init__(self, *tensors, batch_size=32, shuffle=False):\n",
        "        \"\"\"\n",
        "        Initialize a FastTensorDataLoader.\n",
        "        :param *tensors: tensors to store. Must have the same length @ dim 0.\n",
        "        :param batch_size: batch size to load.\n",
        "        :param shuffle: if True, shuffle the data *in-place* whenever an\n",
        "            iterator is created out of this object.\n",
        "        :returns: A FastTensorDataLoader.\n",
        "        \"\"\"\n",
        "        assert all(t.shape[0] == tensors[0].shape[0] for t in tensors)\n",
        "        self.tensors = tensors\n",
        "\n",
        "        self.dataset_len = self.tensors[0].shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Calculate # batches\n",
        "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
        "        if remainder > 0:\n",
        "            n_batches += 1\n",
        "        self.n_batches = n_batches\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            r = torch.randperm(self.dataset_len)\n",
        "            self.tensors = [t[r] for t in self.tensors]\n",
        "        self.i = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.i >= self.dataset_len:\n",
        "            raise StopIteration\n",
        "        batch = tuple(t[self.i:self.i+self.batch_size] for t in self.tensors)\n",
        "        self.i += self.batch_size\n",
        "        return batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "def prepare_fast_dataloader(\n",
        "    D : Dataset,\n",
        "    split : str,\n",
        "    batch_size: int\n",
        "):\n",
        "    if D.X_cat is not None:\n",
        "        if D.X_num is not None:\n",
        "            X = torch.from_numpy(np.concatenate([D.X_num[split], D.X_cat[split]], axis=1)).float()\n",
        "        else:\n",
        "            X = torch.from_numpy(D.X_cat[split]).float()\n",
        "    else:\n",
        "        X = torch.from_numpy(D.X_num[split]).float()\n",
        "    y = torch.from_numpy(D.y[split])\n",
        "    dataloader = FastTensorDataLoader(X, y, batch_size=batch_size, shuffle=(split=='train'))\n",
        "    while True:\n",
        "        yield from dataloader\n",
        "\n",
        "def prepare_fast_torch_dataloader(\n",
        "    D : Dataset,\n",
        "    split : str,\n",
        "    batch_size: int\n",
        "):\n",
        "    if D.X_cat is not None:\n",
        "        X = torch.from_numpy(np.concatenate([D.X_num[split], D.X_cat[split]], axis=1)).float()\n",
        "    else:\n",
        "        X = torch.from_numpy(D.X_num[split]).float()\n",
        "    y = torch.from_numpy(D.y[split])\n",
        "    dataloader = FastTensorDataLoader(X, y, batch_size=batch_size, shuffle=(split=='train'))\n",
        "    return dataloader\n",
        "\n",
        "def round_columns(X_real, X_synth, columns):\n",
        "    for col in columns:\n",
        "        uniq = np.unique(X_real[:,col])\n",
        "        dist = cdist(X_synth[:, col][:, np.newaxis].astype(float), uniq[:, np.newaxis].astype(float))\n",
        "        X_synth[:, col] = uniq[dist.argmin(axis=1)]\n",
        "    return X_synth\n",
        "\n",
        "def concat_features(D : Dataset):\n",
        "    if D.X_num is None:\n",
        "        assert D.X_cat is not None\n",
        "        X = {k: pd.DataFrame(v, columns=range(D.n_features)) for k, v in D.X_cat.items()}\n",
        "    elif D.X_cat is None:\n",
        "        assert D.X_num is not None\n",
        "        X = {k: pd.DataFrame(v, columns=range(D.n_features)) for k, v in D.X_num.items()}\n",
        "    else:\n",
        "        X = {\n",
        "            part: pd.concat(\n",
        "                [\n",
        "                    pd.DataFrame(D.X_num[part], columns=range(D.n_num_features)),\n",
        "                    pd.DataFrame(\n",
        "                        D.X_cat[part],\n",
        "                        columns=range(D.n_num_features, D.n_features),\n",
        "                    ),\n",
        "                ],\n",
        "                axis=1,\n",
        "            )\n",
        "            for part in D.y.keys()\n",
        "        }\n",
        "\n",
        "    return X\n",
        "\n",
        "def concat_to_pd(X_num, X_cat, y):\n",
        "    if X_num is None:\n",
        "        return pd.concat([\n",
        "            pd.DataFrame(X_cat, columns=list(range(X_cat.shape[1]))),\n",
        "            pd.DataFrame(y, columns=['y'])\n",
        "        ], axis=1)\n",
        "    if X_cat is not None:\n",
        "        return pd.concat([\n",
        "            pd.DataFrame(X_num, columns=list(range(X_num.shape[1]))),\n",
        "            pd.DataFrame(X_cat, columns=list(range(X_num.shape[1], X_num.shape[1] + X_cat.shape[1]))),\n",
        "            pd.DataFrame(y, columns=['y'])\n",
        "        ], axis=1)\n",
        "    return pd.concat([\n",
        "            pd.DataFrame(X_num, columns=list(range(X_num.shape[1]))),\n",
        "            pd.DataFrame(y, columns=['y'])\n",
        "        ], axis=1)\n",
        "\n",
        "def read_pure_data(path, split='train'):\n",
        "    y = np.load(os.path.join(path, f'y_{split}.npy'), allow_pickle=True)\n",
        "    X_num = None\n",
        "    X_cat = None\n",
        "    if os.path.exists(os.path.join(path, f'X_num_{split}.npy')):\n",
        "        X_num = np.load(os.path.join(path, f'X_num_{split}.npy'), allow_pickle=True)\n",
        "    if os.path.exists(os.path.join(path, f'X_cat_{split}.npy')):\n",
        "        X_cat = np.load(os.path.join(path, f'X_cat_{split}.npy'), allow_pickle=True)\n",
        "\n",
        "    return X_num, X_cat, y\n",
        "\n",
        "def read_changed_val(path, val_size=0.2):\n",
        "    path = Path(path)\n",
        "    X_num_train, X_cat_train, y_train = read_pure_data(path, 'train')\n",
        "    X_num_val, X_cat_val, y_val = read_pure_data(path, 'val')\n",
        "    is_regression = load_json(path / 'info.json')['task_type'] == 'regression'\n",
        "\n",
        "    y = np.concatenate([y_train, y_val], axis=0)\n",
        "\n",
        "    ixs = np.arange(y.shape[0])\n",
        "    if is_regression:\n",
        "        train_ixs, val_ixs = train_test_split(ixs, test_size=val_size, random_state=777)\n",
        "    else:\n",
        "        train_ixs, val_ixs = train_test_split(ixs, test_size=val_size, random_state=777, stratify=y)\n",
        "    y_train = y[train_ixs]\n",
        "    y_val = y[val_ixs]\n",
        "\n",
        "    if X_num_train is not None:\n",
        "        X_num = np.concatenate([X_num_train, X_num_val], axis=0)\n",
        "        X_num_train = X_num[train_ixs]\n",
        "        X_num_val = X_num[val_ixs]\n",
        "\n",
        "    if X_cat_train is not None:\n",
        "        X_cat = np.concatenate([X_cat_train, X_cat_val], axis=0)\n",
        "        X_cat_train = X_cat[train_ixs]\n",
        "        X_cat_val = X_cat[val_ixs]\n",
        "\n",
        "    return X_num_train, X_cat_train, y_train, X_num_val, X_cat_val, y_val\n",
        "\n",
        "#############\n",
        "\n",
        "def load_dataset_info(dataset_dir_name: str) -> Dict[str, Any]:\n",
        "    path = Path(\"data/\" + dataset_dir_name)\n",
        "    info = util.load_json(path / 'info.json')\n",
        "    info['size'] = info['train_size'] + info['val_size'] + info['test_size']\n",
        "    info['n_features'] = info['n_num_features'] + info['n_cat_features']\n",
        "    info['path'] = path\n",
        "    return info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcbS4sYsrOrx",
        "outputId": "3902d0ea-14af-40b7-e132-3744e19a4161"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lib/data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/sample.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import zero\n",
        "import os\n",
        "from tab_ddpm.gaussian_multinomial_diffsuion import GaussianMultinomialDiffusion\n",
        "from tab_ddpm.utils import FoundNANsError\n",
        "from utils_train import get_model, make_dataset\n",
        "from lib import round_columns\n",
        "import lib\n",
        "\n",
        "def to_good_ohe(ohe, X):\n",
        "    indices = np.cumsum([0] + ohe._n_features_outs)\n",
        "    Xres = []\n",
        "    for i in range(1, len(indices)):\n",
        "        x_ = np.max(X[:, indices[i - 1]:indices[i]], axis=1)\n",
        "        t = X[:, indices[i - 1]:indices[i]] - x_.reshape(-1, 1)\n",
        "        Xres.append(np.where(t >= 0, 1, 0))\n",
        "    return np.hstack(Xres)\n",
        "\n",
        "def sample(\n",
        "    parent_dir,\n",
        "    real_data_path = 'data/higgs-small',\n",
        "    batch_size = 2000,\n",
        "    num_samples = 0,\n",
        "    model_type = 'mlp',\n",
        "    model_params = None,\n",
        "    model_path = None,\n",
        "    num_timesteps = 1000,\n",
        "    gaussian_loss_type = 'mse',\n",
        "    scheduler = 'cosine',\n",
        "    T_dict = None,\n",
        "    num_numerical_features = 0,\n",
        "    disbalance = None,\n",
        "    device = torch.device('cuda:1'),\n",
        "    seed = 0,\n",
        "    change_val = False\n",
        "):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    T = lib.Transformations(**T_dict)\n",
        "    D = make_dataset(\n",
        "        real_data_path,\n",
        "        T,\n",
        "        num_classes=model_params['num_classes'],\n",
        "        is_y_cond=model_params['is_y_cond'],\n",
        "        change_val=change_val\n",
        "    )\n",
        "\n",
        "    K = np.array(D.get_category_sizes('train'))\n",
        "    if len(K) == 0 or T_dict['cat_encoding'] == 'one-hot':\n",
        "        K = np.array([0])\n",
        "\n",
        "    num_numerical_features_ = D.X_num['train'].shape[1] if D.X_num is not None else 0\n",
        "    d_in = np.sum(K) + num_numerical_features_\n",
        "    model_params['d_in'] = int(d_in)\n",
        "    model = get_model(\n",
        "        model_type,\n",
        "        model_params,\n",
        "        num_numerical_features_,\n",
        "        category_sizes=D.get_category_sizes('train')\n",
        "    )\n",
        "\n",
        "    model.load_state_dict(\n",
        "        torch.load(model_path, map_location=\"cpu\")\n",
        "    )\n",
        "\n",
        "    diffusion = GaussianMultinomialDiffusion(\n",
        "        K,\n",
        "        num_numerical_features=num_numerical_features_,\n",
        "        denoise_fn=model, num_timesteps=num_timesteps,\n",
        "        gaussian_loss_type=gaussian_loss_type, scheduler=scheduler, device=device\n",
        "    )\n",
        "\n",
        "    diffusion.to(device)\n",
        "    diffusion.eval()\n",
        "\n",
        "    _, empirical_class_dist = torch.unique(torch.from_numpy(D.y['train']), return_counts=True)\n",
        "    # empirical_class_dist = empirical_class_dist.float() + torch.tensor([-5000., 10000.]).float()\n",
        "    if disbalance == 'fix':\n",
        "        empirical_class_dist[0], empirical_class_dist[1] = empirical_class_dist[1], empirical_class_dist[0]\n",
        "        x_gen, y_gen = diffusion.sample_all(num_samples, batch_size, empirical_class_dist.float(), ddim=False)\n",
        "\n",
        "    elif disbalance == 'fill':\n",
        "        ix_major = empirical_class_dist.argmax().item()\n",
        "        val_major = empirical_class_dist[ix_major].item()\n",
        "        x_gen, y_gen = [], []\n",
        "        for i in range(empirical_class_dist.shape[0]):\n",
        "            if i == ix_major:\n",
        "                continue\n",
        "            distrib = torch.zeros_like(empirical_class_dist)\n",
        "            distrib[i] = 1\n",
        "            num_samples = val_major - empirical_class_dist[i].item()\n",
        "            x_temp, y_temp = diffusion.sample_all(num_samples, batch_size, distrib.float(), ddim=False)\n",
        "            x_gen.append(x_temp)\n",
        "            y_gen.append(y_temp)\n",
        "\n",
        "        x_gen = torch.cat(x_gen, dim=0)\n",
        "        y_gen = torch.cat(y_gen, dim=0)\n",
        "\n",
        "    else:\n",
        "        x_gen, y_gen = diffusion.sample_all(num_samples, batch_size, empirical_class_dist.float(), ddim=False)\n",
        "\n",
        "\n",
        "    # try:\n",
        "    # except FoundNANsError as ex:\n",
        "    #     print(\"Found NaNs during sampling!\")\n",
        "    #     loader = lib.prepare_fast_dataloader(D, 'train', 8)\n",
        "    #     x_gen = next(loader)[0]\n",
        "    #     y_gen = torch.multinomial(\n",
        "    #         empirical_class_dist.float(),\n",
        "    #         num_samples=8,\n",
        "    #         replacement=True\n",
        "    #     )\n",
        "    X_gen, y_gen = x_gen.numpy(), y_gen.numpy()\n",
        "\n",
        "    ###\n",
        "    # X_num_unnorm = X_gen[:, :num_numerical_features]\n",
        "    # lo = np.percentile(X_num_unnorm, 2.5, axis=0)\n",
        "    # hi = np.percentile(X_num_unnorm, 97.5, axis=0)\n",
        "    # idx = (lo < X_num_unnorm) & (hi > X_num_unnorm)\n",
        "    # X_gen = X_gen[np.all(idx, axis=1)]\n",
        "    # y_gen = y_gen[np.all(idx, axis=1)]\n",
        "    ###\n",
        "\n",
        "    num_numerical_features = num_numerical_features + int(D.is_regression and not model_params[\"is_y_cond\"])\n",
        "\n",
        "    X_num_ = X_gen\n",
        "    if num_numerical_features < X_gen.shape[1]:\n",
        "        np.save(os.path.join(parent_dir, 'X_cat_unnorm'), X_gen[:, num_numerical_features:])\n",
        "        # _, _, cat_encoder = lib.cat_encode({'train': X_cat_real}, T_dict['cat_encoding'], y_real, T_dict['seed'], True)\n",
        "        if T_dict['cat_encoding'] == 'one-hot':\n",
        "            X_gen[:, num_numerical_features:] = to_good_ohe(D.cat_transform.steps[0][1], X_num_[:, num_numerical_features:])\n",
        "        X_cat = D.cat_transform.inverse_transform(X_gen[:, num_numerical_features:])\n",
        "\n",
        "    if num_numerical_features_ != 0:\n",
        "        # _, normalize = lib.normalize({'train' : X_num_real}, T_dict['normalization'], T_dict['seed'], True)\n",
        "        np.save(os.path.join(parent_dir, 'X_num_unnorm'), X_gen[:, :num_numerical_features])\n",
        "        X_num_ = D.num_transform.inverse_transform(X_gen[:, :num_numerical_features])\n",
        "        X_num = X_num_[:, :num_numerical_features]\n",
        "\n",
        "        X_num_real = np.load(os.path.join(real_data_path, \"X_num_train.npy\"), allow_pickle=True)\n",
        "        disc_cols = []\n",
        "        for col in range(X_num_real.shape[1]):\n",
        "            uniq_vals = np.unique(X_num_real[:, col])\n",
        "            if len(uniq_vals) <= 32 and ((uniq_vals - np.round(uniq_vals)) == 0).all():\n",
        "                disc_cols.append(col)\n",
        "        print(\"Discrete cols:\", disc_cols)\n",
        "        if model_params['num_classes'] == 0:\n",
        "            y_gen = X_num[:, 0]\n",
        "            X_num = X_num[:, 1:]\n",
        "        if len(disc_cols):\n",
        "            X_num = round_columns(X_num_real, X_num, disc_cols)\n",
        "\n",
        "    if num_numerical_features != 0:\n",
        "        print(\"Num shape: \", X_num.shape)\n",
        "        np.save(os.path.join(parent_dir, 'X_num_train'), X_num)\n",
        "    if num_numerical_features < X_gen.shape[1]:\n",
        "        np.save(os.path.join(parent_dir, 'X_cat_train'), X_cat)\n",
        "    np.save(os.path.join(parent_dir, 'y_train'), y_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMje8wM71DGN",
        "outputId": "237edb25-24e1-4c5a-fcca-9a234f4bf737"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/sample.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !conda activate tddpm\n",
        "# !cd $PROJECT_DIR\n",
        "# !wget \"https://www.dropbox.com/s/rpckvcs3vx7j605/data.tar?dl=0\" -O data.tar\n",
        "# !tar -xvf data.tar"
      ],
      "metadata": {
        "id": "KCXcRPwLJpQ8",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"data/credit\", exist_ok=True)\n",
        "os.makedirs(\"exp/credit\", exist_ok=True)\n",
        "\n",
        "data_url = 'https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip'\n",
        "response = requests.get(data_url)\n",
        "zip_file = ZipFile(BytesIO(response.content))\n",
        "zip_file.extractall('data/credit')\n",
        "\n",
        "df = pd.read_excel('data/credit/default of credit card clients.xls', skiprows=[0])\n",
        "df.to_csv('data/credit/credit.csv', index=False)"
      ],
      "metadata": {
        "id": "3G3aXeYYFn2Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Session reset, re-import required libraries and re-run the operation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Re-load the uploaded CSV file\n",
        "df = pd.read_csv(\"data/credit/credit.csv\")\n",
        "\n",
        "# Drop ID column\n",
        "df = df.drop(columns=[\"ID\"])\n",
        "\n",
        "# Define numerical, categorical, and target columns\n",
        "num_cols = [\"LIMIT_BAL\", \"AGE\",\n",
        "            \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\",\n",
        "            \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]\n",
        "cat_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\",\n",
        "            \"PAY_4\", \"PAY_5\", \"PAY_6\"]\n",
        "target_col = \"default payment next month\"\n",
        "\n",
        "# Split into features and labels\n",
        "X_num = df[num_cols].values\n",
        "X_cat = df[cat_cols].values\n",
        "y = df[target_col].values\n",
        "\n",
        "# First split: separate out test set (20%)\n",
        "X_num_temp, X_num_test, X_cat_temp, X_cat_test, y_temp, y_test = train_test_split(\n",
        "    X_num, X_cat, y, test_size=0.2, random_state=0, stratify=y)\n",
        "\n",
        "# Second split: validation set from remaining (20% of remaining = 16% overall)\n",
        "X_num_train, X_num_val, X_cat_train, X_cat_val, y_train, y_val = train_test_split(\n",
        "    X_num_temp, X_cat_temp, y_temp, test_size=0.2, random_state=0, stratify=y_temp)\n",
        "\n",
        "# Create save directory\n",
        "save_dir = \"data/credit\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save 9 .npy files\n",
        "np.save(os.path.join(save_dir, \"X_num_train.npy\"), X_num_train)\n",
        "np.save(os.path.join(save_dir, \"X_num_val.npy\"), X_num_val)\n",
        "np.save(os.path.join(save_dir, \"X_num_test.npy\"), X_num_test)\n",
        "\n",
        "np.save(os.path.join(save_dir, \"X_cat_train.npy\"), X_cat_train)\n",
        "np.save(os.path.join(save_dir, \"X_cat_val.npy\"), X_cat_val)\n",
        "np.save(os.path.join(save_dir, \"X_cat_test.npy\"), X_cat_test)\n",
        "\n",
        "np.save(os.path.join(save_dir, \"y_train.npy\"), y_train)\n",
        "np.save(os.path.join(save_dir, \"y_val.npy\"), y_val)\n",
        "np.save(os.path.join(save_dir, \"y_test.npy\"), y_test)\n",
        "\n",
        "# Return confirmation summary\n",
        "{\n",
        "    \"train_size\": len(y_train),\n",
        "    \"val_size\": len(y_val),\n",
        "    \"test_size\": len(y_test),\n",
        "    \"saved_to\": save_dir\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSvD6ir4ouWp",
        "outputId": "13ecb032-6f88-4c4e-bdf9-48992c72e4ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_size': 19200,\n",
              " 'val_size': 4800,\n",
              " 'test_size': 6000,\n",
              " 'saved_to': 'data/credit'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "info = {\n",
        "    \"name\": \"Credit\",\n",
        "    \"id\": \"credit--default\",\n",
        "    \"task_type\": \"binclass\",\n",
        "    \"n_num_features\": 14,\n",
        "    \"n_cat_features\": 9,\n",
        "    \"train_size\": 19200,\n",
        "    \"val_size\": 4800,\n",
        "    \"test_size\": 6000\n",
        "}\n",
        "\n",
        "save_path = \"data/credit/info.json\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(info, f, indent=4)\n",
        "\n",
        "save_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4IbPrP47rkdl",
        "outputId": "ddc9aaff-05cc-41a0-b2cb-f52a2361615e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/credit/info.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"exp/credit\", exist_ok=True)\n",
        "\n",
        "config_text = \"\"\"\n",
        "parent_dir = \"exp/credit/check\"\n",
        "real_data_path = \"data/credit/\"\n",
        "num_numerical_features = 14\n",
        "model_type = \"mlp\"\n",
        "seed = 0\n",
        "device = \"cuda:0\"\n",
        "\n",
        "[model_params]\n",
        "num_classes = 2\n",
        "is_y_cond = true\n",
        "\n",
        "[model_params.rtdl_params]\n",
        "d_layers = [\n",
        "    256,\n",
        "    1024,\n",
        "    1024,\n",
        "    1024,\n",
        "    1024,\n",
        "    256\n",
        "]\n",
        "dropout = 0.0\n",
        "\n",
        "[diffusion_params]\n",
        "num_timesteps = 1000\n",
        "gaussian_loss_type = \"mse\"\n",
        "scheduler = \"cosine\"\n",
        "\n",
        "[train.main]\n",
        "steps = 19200\n",
        "lr = 0.0005\n",
        "weight_decay = 1e-05\n",
        "batch_size = 4096\n",
        "\n",
        "[train.T]\n",
        "seed = 0\n",
        "normalization = \"minmax\"\n",
        "num_nan_policy = \"__none__\"\n",
        "cat_nan_policy = \"__none__\"\n",
        "cat_min_frequency = \"__none__\"\n",
        "cat_encoding = \"__none__\"\n",
        "y_policy = \"default\"\n",
        "\n",
        "[sample]\n",
        "num_samples = 30000\n",
        "batch_size = 5000\n",
        "seed = 0\n",
        "\n",
        "[eval.type]\n",
        "eval_model = \"catboost\"\n",
        "eval_type = \"synthetic\"\n",
        "\n",
        "[eval.T]\n",
        "seed = 0\n",
        "normalization = \"__none__\"\n",
        "num_nan_policy = \"__none__\"\n",
        "cat_nan_policy = \"__none__\"\n",
        "cat_min_frequency = \"__none__\"\n",
        "cat_encoding = \"__none__\"\n",
        "y_policy = \"default\"\n",
        "\"\"\"\n",
        "\n",
        "with open(\"exp/credit/config.toml\", \"w\") as f:\n",
        "    f.write(config_text)"
      ],
      "metadata": {
        "id": "L91GvjfKF7Kl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/pipeline.py --config exp/credit/config.toml --train --sample"
      ],
      "metadata": {
        "id": "2yFs5XjZYz6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bff9037-217c-43d4-e994-9e9e7410e687"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2  7  4 11 11 11 11 10 10]\n",
            "91\n",
            "{'num_classes': 2, 'is_y_cond': True, 'rtdl_params': {'d_layers': [256, 1024, 1024, 1024, 1024, 256], 'dropout': 0.0}, 'd_in': 91}\n",
            "mlp\n",
            "Step 500/19200 MLoss: 0.7621 GLoss: 0.9913 Sum: 1.7534\n",
            "Step 1000/19200 MLoss: 0.7418 GLoss: 0.618 Sum: 1.3598\n",
            "Step 1500/19200 MLoss: 0.738 GLoss: 0.455 Sum: 1.193\n",
            "Step 2000/19200 MLoss: 0.7349 GLoss: 0.2667 Sum: 1.0016\n",
            "Step 2500/19200 MLoss: 0.7316 GLoss: 0.17 Sum: 0.9016000000000001\n",
            "Step 3000/19200 MLoss: 0.7246 GLoss: 0.0885 Sum: 0.8131\n",
            "Step 3500/19200 MLoss: 0.7209 GLoss: 0.0743 Sum: 0.7952\n",
            "Step 4000/19200 MLoss: 0.7211 GLoss: 0.0694 Sum: 0.7905\n",
            "Step 4500/19200 MLoss: 0.7233 GLoss: 0.0646 Sum: 0.7879\n",
            "Step 5000/19200 MLoss: 0.7184 GLoss: 0.0604 Sum: 0.7788\n",
            "Step 5500/19200 MLoss: 0.717 GLoss: 0.0582 Sum: 0.7752\n",
            "Step 6000/19200 MLoss: 0.7169 GLoss: 0.054 Sum: 0.7709\n",
            "Step 6500/19200 MLoss: 0.7171 GLoss: 0.0542 Sum: 0.7713\n",
            "Step 7000/19200 MLoss: 0.7176 GLoss: 0.0575 Sum: 0.7751\n",
            "Step 7500/19200 MLoss: 0.7162 GLoss: 0.0528 Sum: 0.7689999999999999\n",
            "Step 8000/19200 MLoss: 0.7126 GLoss: 0.0512 Sum: 0.7638\n",
            "Step 8500/19200 MLoss: 0.7117 GLoss: 0.05 Sum: 0.7617\n",
            "Step 9000/19200 MLoss: 0.7114 GLoss: 0.0479 Sum: 0.7593000000000001\n",
            "Step 9500/19200 MLoss: 0.7096 GLoss: 0.0466 Sum: 0.7562\n",
            "Step 10000/19200 MLoss: 0.7084 GLoss: 0.0442 Sum: 0.7526\n",
            "Step 10500/19200 MLoss: 0.7079 GLoss: 0.0433 Sum: 0.7512\n",
            "Step 11000/19200 MLoss: 0.7157 GLoss: 0.0444 Sum: 0.7601\n",
            "Step 11500/19200 MLoss: 0.7129 GLoss: 0.0423 Sum: 0.7552\n",
            "Step 12000/19200 MLoss: 0.7071 GLoss: 0.0407 Sum: 0.7477999999999999\n",
            "Step 12500/19200 MLoss: 0.7076 GLoss: 0.0389 Sum: 0.7465\n",
            "Step 13000/19200 MLoss: 0.7058 GLoss: 0.0392 Sum: 0.745\n",
            "Step 13500/19200 MLoss: 0.709 GLoss: 0.0384 Sum: 0.7474\n",
            "Step 14000/19200 MLoss: 0.7104 GLoss: 0.038 Sum: 0.7484000000000001\n",
            "Step 14500/19200 MLoss: 0.7085 GLoss: 0.0407 Sum: 0.7492\n",
            "Step 15000/19200 MLoss: 0.7051 GLoss: 0.0362 Sum: 0.7413\n",
            "Step 15500/19200 MLoss: 0.7032 GLoss: 0.0354 Sum: 0.7386\n",
            "Step 16000/19200 MLoss: 0.7084 GLoss: 0.0344 Sum: 0.7428\n",
            "Step 16500/19200 MLoss: 0.7067 GLoss: 0.0357 Sum: 0.7424\n",
            "Step 17000/19200 MLoss: 0.7036 GLoss: 0.0334 Sum: 0.737\n",
            "Step 17500/19200 MLoss: 0.7019 GLoss: 0.0331 Sum: 0.735\n",
            "Step 18000/19200 MLoss: 0.7016 GLoss: 0.0327 Sum: 0.7343\n",
            "Step 18500/19200 MLoss: 0.7042 GLoss: 0.0324 Sum: 0.7366\n",
            "Step 19000/19200 MLoss: 0.6975 GLoss: 0.0317 Sum: 0.7292\n",
            "mlp\n",
            "Sample timestep    0\n",
            "Sample timestep    0\n",
            "Sample timestep    0\n",
            "Sample timestep    0\n",
            "Sample timestep    0\n",
            "Sample timestep    0\n",
            "Discrete cols: []\n",
            "Num shape:  (30000, 14)\n",
            "Elapsed time: 0.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "parent_dir = \"exp/credit/check\"\n",
        "\n",
        "X_num = np.load(os.path.join(parent_dir, \"X_num_train.npy\"))\n",
        "X_cat = np.load(os.path.join(parent_dir, \"X_cat_train.npy\"), allow_pickle=True)\n",
        "y = np.load(os.path.join(parent_dir, \"y_train.npy\"))\n",
        "\n",
        "# num_cols = [\"LIMIT_BAL\", \"AGE\",\n",
        "#             \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\",\n",
        "#             \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]\n",
        "\n",
        "# cat_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\",\n",
        "#             \"PAY_4\", \"PAY_5\", \"PAY_6\"]\n",
        "\n",
        "# target_col = \"default payment next month\"\n",
        "\n",
        "df_num = pd.DataFrame(X_num, columns=num_cols)\n",
        "df_cat = pd.DataFrame(X_cat, columns=cat_cols)\n",
        "df_y = pd.Series(y, name=target_col)\n",
        "\n",
        "df = pd.concat([df_num, df_cat, df_y], axis=1)\n",
        "\n",
        "output_path = os.path.join(parent_dir, \"generated_credit.csv\")\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"CSV has been saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPAbD4Ph4sra",
        "outputId": "265946d0-3e81-4199-9a8e-449992f2f648"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV has been saved to: exp/credit/check/generated_credit.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sdv.evaluation.single_table import evaluate_quality\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "\n",
        "real_data = pd.read_csv(\"data/credit/credit.csv\")\n",
        "real_data = real_data.drop(columns=[\"ID\"])\n",
        "synthetic_data = pd.read_csv(\"exp/credit/check/generated_credit.csv\")\n",
        "\n",
        "target_column = \"default payment next month\"\n",
        "\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(data=real_data)\n",
        "\n",
        "quality_report = evaluate_quality(\n",
        "    real_data=real_data,\n",
        "    synthetic_data=synthetic_data,\n",
        "    metadata=metadata,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCHXoAubCax9",
        "outputId": "e6a21bcb-27d9-4789-ef42-4d1927e7210d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "(1/2) Evaluating Column Shapes: : 100%|██████████| 24/24 [00:00<00:00, 103.33it/s]\n",
            "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 276/276 [00:01<00:00, 139.71it/s]\n",
            "\n",
            "Overall Quality Score: 93.13%\n",
            "\n",
            "Properties:\n",
            "- Column Shapes: 87.0%\n",
            "- Column Pair Trends: 99.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot Column Shapes -> referred to the \"Fidelity Column\" in the paper\n",
        "fig = quality_report.get_visualization(property_name='Column Shapes')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vbTrn5ssDd_o",
        "outputId": "cd1ee170-b1bd-4767-efdd-ab3752ca0c9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9b4f0f3f-d956-4b30-96aa-04dc8ee6c444\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9b4f0f3f-d956-4b30-96aa-04dc8ee6c444\")) {                    Plotly.newPlot(                        \"9b4f0f3f-d956-4b30-96aa-04dc8ee6c444\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"xaxis\":\"x\",\"y\":[0.9084,0.9965999999999999,0.9972333333333333,0.9968333333333333,0.9405,0.9941,0.9927333333333334,0.9938,0.9943666666666666,0.9950666666666667,0.9962333333333334,0.8511,0.8591333333333333,0.8604666666666667,0.8400333333333333,0.8378333333333333,0.8378333333333333,0.6453,0.6261666666666666,0.6624333333333333,0.6548333333333334,0.7223666666666666,0.6782,0.9983333333333333],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.87)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9b4f0f3f-d956-4b30-96aa-04dc8ee6c444');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot Column Pair Trends -> referred to the \"Fidelity Row\" in the paper\n",
        "fig = quality_report.get_visualization(property_name='Column Pair Trends')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "X_HWk9s-DmYQ",
        "outputId": "f31f2f4d-c6ba-4cc5-c3dc-62e38b6409fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3de00a97-d835-48e5-b455-15301cb82ed5\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3de00a97-d835-48e5-b455-15301cb82ed5\")) {                    Plotly.newPlot(                        \"3de00a97-d835-48e5-b455-15301cb82ed5\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"y\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"z\":[[1.0,1.0,0.999,0.993,0.999,0.998,0.998,0.995,0.996,0.999,0.996,0.993,0.995,0.993,0.993,0.991,0.99,1.0,0.992,0.999,0.99,0.99,0.974,0.997],[1.0,1.0,1.0,1.0,0.998,0.996,1.0,1.0,0.995,0.994,0.994,1.0,0.998,0.998,0.995,0.994,0.994,1.0,0.987,0.996,0.993,0.999,0.995,0.995],[0.999,1.0,1.0,0.993,0.999,0.999,0.997,0.999,1.0,0.997,1.0,0.997,0.998,0.999,0.999,1.0,0.998,0.997,0.994,1.0,0.996,1.0,0.993,0.997],[0.993,1.0,0.993,1.0,0.989,1.0,0.997,1.0,0.998,1.0,0.999,0.997,0.997,0.995,0.995,0.994,0.995,0.995,0.992,0.994,0.997,0.999,0.998,0.999],[0.999,0.998,0.999,0.989,1.0,0.996,0.998,0.995,0.996,0.996,0.994,1.0,1.0,0.998,0.998,0.997,0.998,0.998,0.997,0.999,0.992,0.998,0.996,0.996],[0.998,0.996,0.999,1.0,0.996,1.0,0.996,0.998,1.0,0.998,0.999,0.994,0.994,0.991,0.994,0.993,0.992,0.997,0.997,0.998,0.994,0.997,0.992,0.999],[0.998,1.0,0.997,0.997,0.998,0.996,1.0,0.995,0.995,0.999,0.998,0.993,0.992,0.99,0.992,0.99,0.989,1.0,0.998,1.0,0.996,0.999,0.996,0.999],[0.995,1.0,0.999,1.0,0.995,0.998,0.995,1.0,0.997,0.997,1.0,0.99,0.992,0.99,0.992,0.991,0.988,1.0,0.998,0.998,0.997,0.997,0.998,0.997],[0.996,0.995,1.0,0.998,0.996,1.0,0.995,0.997,1.0,0.996,0.997,0.989,0.989,0.987,0.988,0.988,0.984,0.998,0.998,0.996,0.996,0.992,0.999,0.997],[0.999,0.994,0.997,1.0,0.996,0.998,0.999,0.997,0.996,1.0,0.997,0.988,0.988,0.985,0.988,0.99,0.983,1.0,0.994,0.995,0.996,0.99,0.999,0.999],[0.996,0.994,1.0,0.999,0.994,0.999,0.998,1.0,0.997,0.997,1.0,0.988,0.99,0.986,0.989,0.991,0.987,0.999,0.992,0.998,0.997,0.995,0.998,0.999],[0.993,1.0,0.997,0.997,1.0,0.994,0.993,0.99,0.989,0.988,0.988,1.0,0.999,0.984,0.99,0.988,0.984,0.989,0.981,1.0,0.998,0.988,0.975,0.997],[0.995,0.998,0.998,0.997,1.0,0.994,0.992,0.992,0.989,0.988,0.99,0.999,1.0,0.99,0.99,0.991,0.987,0.97,0.979,0.998,0.997,0.988,0.975,0.999],[0.993,0.998,0.999,0.995,0.998,0.991,0.99,0.99,0.987,0.985,0.986,0.984,0.99,1.0,0.992,0.987,0.984,0.982,0.955,0.986,0.999,0.999,0.98,0.998],[0.993,0.995,0.999,0.995,0.998,0.994,0.992,0.992,0.988,0.988,0.989,0.99,0.99,0.992,1.0,0.997,0.998,0.987,0.988,0.971,0.995,0.99,0.982,0.999],[0.991,0.994,1.0,0.994,0.997,0.993,0.99,0.991,0.988,0.99,0.991,0.988,0.991,0.987,0.997,1.0,0.995,0.994,0.987,0.985,0.981,0.982,0.974,0.999],[0.99,0.994,0.998,0.995,0.998,0.992,0.989,0.988,0.984,0.983,0.987,0.984,0.987,0.984,0.998,0.995,1.0,0.998,0.995,0.989,0.989,0.989,0.956,0.998],[1.0,1.0,0.997,0.995,0.998,0.997,1.0,1.0,0.998,1.0,0.999,0.989,0.97,0.982,0.987,0.994,0.998,1.0,0.959,0.974,0.997,0.981,0.989,0.994],[0.992,0.987,0.994,0.992,0.997,0.997,0.998,0.998,0.998,0.994,0.992,0.981,0.979,0.955,0.988,0.987,0.995,0.959,1.0,0.999,0.992,0.987,0.974,0.992],[0.999,0.996,1.0,0.994,0.999,0.998,1.0,0.998,0.996,0.995,0.998,1.0,0.998,0.986,0.971,0.985,0.989,0.974,0.999,1.0,0.995,0.967,0.966,0.993],[0.99,0.993,0.996,0.997,0.992,0.994,0.996,0.997,0.996,0.996,0.997,0.998,0.997,0.999,0.995,0.981,0.989,0.997,0.992,0.995,1.0,0.958,0.954,0.993],[0.99,0.999,1.0,0.999,0.998,0.997,0.999,0.997,0.992,0.99,0.995,0.988,0.988,0.999,0.99,0.982,0.989,0.981,0.987,0.967,0.958,1.0,0.934,0.991],[0.974,0.995,0.993,0.998,0.996,0.992,0.996,0.998,0.999,0.999,0.998,0.975,0.975,0.98,0.982,0.974,0.956,0.989,0.974,0.966,0.954,0.934,1.0,0.986],[0.997,0.995,0.997,0.999,0.996,0.999,0.999,0.997,0.997,0.999,0.999,0.997,0.999,0.998,0.999,0.999,0.998,0.994,0.992,0.993,0.993,0.991,0.986,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.024,-0.222,-0.095,0.142,-0.276,-0.3,-0.296,-0.276,-0.252,-0.242,0.272,0.268,0.27,0.279,0.278,0.27,0.195,0.194,0.211,0.223,0.237,0.272,-0.159],[0.024,1.0,0.014,-0.031,-0.095,-0.049,-0.071,-0.067,-0.05,-0.043,-0.031,-0.033,-0.027,-0.021,-0.012,-0.004,-0.005,0.0,-0.028,-0.001,-0.016,-0.005,0.007,-0.03],[-0.222,0.014,1.0,-0.157,0.177,0.103,0.116,0.113,0.108,0.092,0.081,0.017,0.014,0.011,0.002,-0.007,-0.006,-0.031,-0.043,-0.039,-0.046,-0.041,-0.052,0.033],[-0.095,-0.031,-0.157,1.0,-0.436,0.021,0.029,0.033,0.036,0.036,0.037,-0.018,-0.016,-0.016,-0.013,-0.013,-0.012,0.003,0.007,0.009,-0.006,-0.003,-0.003,-0.023],[0.142,-0.095,0.177,-0.436,1.0,-0.047,-0.055,-0.064,-0.057,-0.063,-0.06,0.056,0.054,0.049,0.047,0.042,0.044,0.03,0.028,0.026,0.036,0.026,0.012,0.006],[-0.276,-0.049,0.103,0.021,-0.047,1.0,0.664,0.571,0.539,0.505,0.472,0.199,0.202,0.197,0.192,0.194,0.193,-0.085,-0.075,-0.074,-0.077,-0.064,-0.074,0.326],[-0.3,-0.071,0.116,0.029,-0.055,0.664,1.0,0.776,0.671,0.625,0.58,0.25,0.252,0.245,0.238,0.241,0.241,-0.081,-0.063,-0.055,-0.055,-0.039,-0.045,0.266],[-0.296,-0.067,0.113,0.033,-0.064,0.571,0.776,1.0,0.771,0.681,0.632,0.228,0.254,0.248,0.243,0.243,0.247,0.002,-0.071,-0.057,-0.051,-0.03,-0.04,0.242],[-0.276,-0.05,0.108,0.036,-0.057,0.539,0.671,0.771,1.0,0.812,0.711,0.225,0.248,0.271,0.27,0.267,0.272,-0.013,0.003,-0.062,-0.051,-0.019,-0.028,0.222],[-0.252,-0.043,0.092,0.036,-0.063,0.505,0.625,0.681,0.812,1.0,0.812,0.231,0.25,0.273,0.296,0.291,0.296,-0.005,0.008,0.018,-0.067,-0.013,-0.022,0.206],[-0.242,-0.031,0.081,0.037,-0.06,0.472,0.58,0.632,0.711,0.812,1.0,0.232,0.248,0.269,0.289,0.31,0.312,-0.003,0.01,0.011,0.012,-0.037,-0.022,0.188],[0.272,-0.033,0.017,-0.018,0.056,0.199,0.25,0.228,0.225,0.231,0.232,1.0,0.954,0.924,0.881,0.854,0.834,0.163,0.137,0.156,0.155,0.192,0.229,-0.025],[0.268,-0.027,0.014,-0.016,0.054,0.202,0.252,0.254,0.248,0.25,0.248,0.954,1.0,0.949,0.912,0.878,0.858,0.22,0.143,0.146,0.141,0.183,0.224,-0.017],[0.27,-0.021,0.011,-0.016,0.049,0.197,0.245,0.248,0.271,0.273,0.269,0.924,0.949,1.0,0.94,0.91,0.886,0.209,0.226,0.157,0.141,0.177,0.222,-0.009],[0.279,-0.012,0.002,-0.013,0.047,0.192,0.238,0.243,0.27,0.296,0.289,0.881,0.912,0.94,1.0,0.933,0.905,0.208,0.231,0.242,0.14,0.181,0.213,-0.012],[0.278,-0.004,-0.007,-0.013,0.042,0.194,0.241,0.243,0.267,0.291,0.31,0.854,0.878,0.91,0.933,1.0,0.936,0.205,0.207,0.221,0.255,0.177,0.216,-0.004],[0.27,-0.005,-0.006,-0.012,0.044,0.193,0.241,0.247,0.272,0.296,0.312,0.834,0.858,0.886,0.905,0.936,1.0,0.196,0.182,0.212,0.228,0.286,0.204,-0.002],[0.195,0.0,-0.031,0.003,0.03,-0.085,-0.081,0.002,-0.013,-0.005,-0.003,0.163,0.22,0.209,0.208,0.205,0.196,1.0,0.203,0.201,0.194,0.187,0.208,-0.085],[0.194,-0.028,-0.043,0.007,0.028,-0.075,-0.063,-0.071,0.003,0.008,0.01,0.137,0.143,0.226,0.231,0.207,0.182,0.203,1.0,0.248,0.165,0.154,0.211,-0.075],[0.211,-0.001,-0.039,0.009,0.026,-0.074,-0.055,-0.057,-0.062,0.018,0.011,0.156,0.146,0.157,0.242,0.221,0.212,0.201,0.248,1.0,0.207,0.226,0.231,-0.07],[0.223,-0.016,-0.046,-0.006,0.036,-0.077,-0.055,-0.051,-0.051,-0.067,0.012,0.155,0.141,0.141,0.14,0.255,0.228,0.194,0.165,0.207,1.0,0.237,0.25,-0.071],[0.237,-0.005,-0.041,-0.003,0.026,-0.064,-0.039,-0.03,-0.019,-0.013,-0.037,0.192,0.183,0.177,0.181,0.177,0.286,0.187,0.154,0.226,0.237,1.0,0.288,-0.074],[0.272,0.007,-0.052,-0.003,0.012,-0.074,-0.045,-0.04,-0.028,-0.022,-0.022,0.229,0.224,0.222,0.213,0.216,0.204,0.208,0.211,0.231,0.25,0.288,1.0,-0.081],[-0.159,-0.03,0.033,-0.023,0.006,0.326,0.266,0.242,0.222,0.206,0.188,-0.025,-0.017,-0.009,-0.012,-0.004,-0.002,-0.085,-0.075,-0.07,-0.071,-0.074,-0.081,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"y\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"z\":[[1.0,0.025,-0.219,-0.108,0.145,-0.271,-0.296,-0.286,-0.267,-0.249,-0.235,0.285,0.278,0.283,0.294,0.296,0.29,0.195,0.178,0.21,0.203,0.217,0.22,-0.154],[0.025,1.0,0.014,-0.031,-0.091,-0.058,-0.071,-0.066,-0.06,-0.055,-0.044,-0.034,-0.031,-0.025,-0.022,-0.017,-0.017,-0.0,-0.001,-0.009,-0.002,-0.002,-0.003,-0.04],[-0.219,0.014,1.0,-0.143,0.175,0.105,0.122,0.114,0.109,0.098,0.082,0.024,0.019,0.013,-0.0,-0.008,-0.009,-0.037,-0.03,-0.04,-0.038,-0.04,-0.037,0.028],[-0.108,-0.031,-0.143,1.0,-0.414,0.02,0.024,0.033,0.033,0.036,0.034,-0.023,-0.022,-0.025,-0.023,-0.025,-0.021,-0.006,-0.008,-0.004,-0.013,-0.001,-0.007,-0.024],[0.145,-0.091,0.175,-0.414,1.0,-0.039,-0.05,-0.053,-0.05,-0.054,-0.049,0.056,0.054,0.054,0.051,0.049,0.048,0.026,0.022,0.029,0.021,0.023,0.019,0.014],[-0.271,-0.058,0.105,0.02,-0.039,1.0,0.672,0.574,0.539,0.509,0.475,0.187,0.19,0.18,0.179,0.181,0.177,-0.079,-0.07,-0.071,-0.064,-0.058,-0.059,0.325],[-0.296,-0.071,0.122,0.024,-0.05,0.672,1.0,0.767,0.662,0.623,0.576,0.235,0.235,0.224,0.222,0.221,0.219,-0.081,-0.059,-0.056,-0.047,-0.037,-0.037,0.264],[-0.286,-0.066,0.114,0.033,-0.053,0.574,0.767,1.0,0.777,0.687,0.633,0.208,0.237,0.227,0.227,0.225,0.222,0.001,-0.067,-0.053,-0.046,-0.036,-0.036,0.235],[-0.267,-0.06,0.109,0.033,-0.05,0.539,0.662,0.777,1.0,0.82,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.009,-0.002,-0.069,-0.043,-0.034,-0.027,0.217],[-0.249,-0.055,0.098,0.036,-0.054,0.509,0.623,0.687,0.82,1.0,0.817,0.207,0.227,0.243,0.272,0.27,0.263,-0.006,-0.003,0.009,-0.058,-0.033,-0.023,0.204],[-0.235,-0.044,0.082,0.034,-0.049,0.475,0.576,0.633,0.716,0.817,1.0,0.207,0.227,0.241,0.266,0.291,0.285,-0.001,-0.005,0.006,0.019,-0.046,-0.025,0.187],[0.285,-0.034,0.024,-0.023,0.056,0.187,0.235,0.208,0.203,0.207,0.207,1.0,0.951,0.892,0.86,0.83,0.803,0.14,0.099,0.157,0.158,0.167,0.179,-0.02],[0.278,-0.031,0.019,-0.022,0.054,0.19,0.235,0.237,0.226,0.227,0.227,0.951,1.0,0.928,0.892,0.86,0.832,0.28,0.101,0.151,0.147,0.158,0.174,-0.014],[0.283,-0.025,0.013,-0.025,0.054,0.18,0.224,0.227,0.245,0.243,0.241,0.892,0.928,1.0,0.924,0.884,0.853,0.244,0.317,0.13,0.143,0.18,0.182,-0.014],[0.294,-0.022,-0.0,-0.023,0.051,0.179,0.222,0.227,0.246,0.272,0.266,0.86,0.892,0.924,1.0,0.94,0.901,0.233,0.208,0.3,0.13,0.16,0.178,-0.01],[0.296,-0.017,-0.008,-0.025,0.049,0.181,0.221,0.225,0.243,0.27,0.291,0.83,0.86,0.884,0.94,1.0,0.946,0.217,0.181,0.252,0.293,0.142,0.164,-0.007],[0.29,-0.017,-0.009,-0.021,0.048,0.177,0.219,0.222,0.239,0.263,0.285,0.803,0.832,0.853,0.901,0.946,1.0,0.2,0.173,0.234,0.25,0.308,0.115,-0.005],[0.195,-0.0,-0.037,-0.006,0.026,-0.079,-0.081,0.001,-0.009,-0.006,-0.001,0.14,0.28,0.244,0.233,0.217,0.2,1.0,0.286,0.252,0.2,0.148,0.186,-0.073],[0.178,-0.001,-0.03,-0.008,0.022,-0.07,-0.059,-0.067,-0.002,-0.003,-0.005,0.099,0.101,0.317,0.208,0.181,0.173,0.286,1.0,0.245,0.18,0.181,0.158,-0.059],[0.21,-0.009,-0.04,-0.004,0.029,-0.071,-0.056,-0.053,-0.069,0.009,0.006,0.157,0.151,0.13,0.3,0.252,0.234,0.252,0.245,1.0,0.216,0.159,0.163,-0.056],[0.203,-0.002,-0.038,-0.013,0.021,-0.064,-0.047,-0.046,-0.043,-0.058,0.019,0.158,0.147,0.143,0.13,0.293,0.25,0.2,0.18,0.216,1.0,0.152,0.158,-0.057],[0.217,-0.002,-0.04,-0.001,0.023,-0.058,-0.037,-0.036,-0.034,-0.033,-0.046,0.167,0.158,0.18,0.16,0.142,0.308,0.148,0.181,0.159,0.152,1.0,0.155,-0.055],[0.22,-0.003,-0.037,-0.007,0.019,-0.059,-0.037,-0.036,-0.027,-0.023,-0.025,0.179,0.174,0.182,0.178,0.164,0.115,0.186,0.158,0.163,0.158,0.155,1.0,-0.053],[-0.154,-0.04,0.028,-0.024,0.014,0.325,0.264,0.235,0.217,0.204,0.187,-0.02,-0.014,-0.014,-0.01,-0.007,-0.005,-0.073,-0.059,-0.056,-0.057,-0.055,-0.053,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.025,-0.219,-0.108,0.145,-0.271,-0.296,-0.286,-0.267,-0.249,-0.235,0.285,0.278,0.283,0.294,0.296,0.29,0.195,0.178,0.21,0.203,0.217,0.22,-0.154],[0.025,1.0,0.014,-0.031,-0.091,-0.058,-0.071,-0.066,-0.06,-0.055,-0.044,-0.034,-0.031,-0.025,-0.022,-0.017,-0.017,-0.0,-0.001,-0.009,-0.002,-0.002,-0.003,-0.04],[-0.219,0.014,1.0,-0.143,0.175,0.105,0.122,0.114,0.109,0.098,0.082,0.024,0.019,0.013,-0.0,-0.008,-0.009,-0.037,-0.03,-0.04,-0.038,-0.04,-0.037,0.028],[-0.108,-0.031,-0.143,1.0,-0.414,0.02,0.024,0.033,0.033,0.036,0.034,-0.023,-0.022,-0.025,-0.023,-0.025,-0.021,-0.006,-0.008,-0.004,-0.013,-0.001,-0.007,-0.024],[0.145,-0.091,0.175,-0.414,1.0,-0.039,-0.05,-0.053,-0.05,-0.054,-0.049,0.056,0.054,0.054,0.051,0.049,0.048,0.026,0.022,0.029,0.021,0.023,0.019,0.014],[-0.271,-0.058,0.105,0.02,-0.039,1.0,0.672,0.574,0.539,0.509,0.475,0.187,0.19,0.18,0.179,0.181,0.177,-0.079,-0.07,-0.071,-0.064,-0.058,-0.059,0.325],[-0.296,-0.071,0.122,0.024,-0.05,0.672,1.0,0.767,0.662,0.623,0.576,0.235,0.235,0.224,0.222,0.221,0.219,-0.081,-0.059,-0.056,-0.047,-0.037,-0.037,0.264],[-0.286,-0.066,0.114,0.033,-0.053,0.574,0.767,1.0,0.777,0.687,0.633,0.208,0.237,0.227,0.227,0.225,0.222,0.001,-0.067,-0.053,-0.046,-0.036,-0.036,0.235],[-0.267,-0.06,0.109,0.033,-0.05,0.539,0.662,0.777,1.0,0.82,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.009,-0.002,-0.069,-0.043,-0.034,-0.027,0.217],[-0.249,-0.055,0.098,0.036,-0.054,0.509,0.623,0.687,0.82,1.0,0.817,0.207,0.227,0.243,0.272,0.27,0.263,-0.006,-0.003,0.009,-0.058,-0.033,-0.023,0.204],[-0.235,-0.044,0.082,0.034,-0.049,0.475,0.576,0.633,0.716,0.817,1.0,0.207,0.227,0.241,0.266,0.291,0.285,-0.001,-0.005,0.006,0.019,-0.046,-0.025,0.187],[0.285,-0.034,0.024,-0.023,0.056,0.187,0.235,0.208,0.203,0.207,0.207,1.0,0.951,0.892,0.86,0.83,0.803,0.14,0.099,0.157,0.158,0.167,0.179,-0.02],[0.278,-0.031,0.019,-0.022,0.054,0.19,0.235,0.237,0.226,0.227,0.227,0.951,1.0,0.928,0.892,0.86,0.832,0.28,0.101,0.151,0.147,0.158,0.174,-0.014],[0.283,-0.025,0.013,-0.025,0.054,0.18,0.224,0.227,0.245,0.243,0.241,0.892,0.928,1.0,0.924,0.884,0.853,0.244,0.317,0.13,0.143,0.18,0.182,-0.014],[0.294,-0.022,-0.0,-0.023,0.051,0.179,0.222,0.227,0.246,0.272,0.266,0.86,0.892,0.924,1.0,0.94,0.901,0.233,0.208,0.3,0.13,0.16,0.178,-0.01],[0.296,-0.017,-0.008,-0.025,0.049,0.181,0.221,0.225,0.243,0.27,0.291,0.83,0.86,0.884,0.94,1.0,0.946,0.217,0.181,0.252,0.293,0.142,0.164,-0.007],[0.29,-0.017,-0.009,-0.021,0.048,0.177,0.219,0.222,0.239,0.263,0.285,0.803,0.832,0.853,0.901,0.946,1.0,0.2,0.173,0.234,0.25,0.308,0.115,-0.005],[0.195,-0.0,-0.037,-0.006,0.026,-0.079,-0.081,0.001,-0.009,-0.006,-0.001,0.14,0.28,0.244,0.233,0.217,0.2,1.0,0.286,0.252,0.2,0.148,0.186,-0.073],[0.178,-0.001,-0.03,-0.008,0.022,-0.07,-0.059,-0.067,-0.002,-0.003,-0.005,0.099,0.101,0.317,0.208,0.181,0.173,0.286,1.0,0.245,0.18,0.181,0.158,-0.059],[0.21,-0.009,-0.04,-0.004,0.029,-0.071,-0.056,-0.053,-0.069,0.009,0.006,0.157,0.151,0.13,0.3,0.252,0.234,0.252,0.245,1.0,0.216,0.159,0.163,-0.056],[0.203,-0.002,-0.038,-0.013,0.021,-0.064,-0.047,-0.046,-0.043,-0.058,0.019,0.158,0.147,0.143,0.13,0.293,0.25,0.2,0.18,0.216,1.0,0.152,0.158,-0.057],[0.217,-0.002,-0.04,-0.001,0.023,-0.058,-0.037,-0.036,-0.034,-0.033,-0.046,0.167,0.158,0.18,0.16,0.142,0.308,0.148,0.181,0.159,0.152,1.0,0.155,-0.055],[0.22,-0.003,-0.037,-0.007,0.019,-0.059,-0.037,-0.036,-0.027,-0.023,-0.025,0.179,0.174,0.182,0.178,0.164,0.115,0.186,0.158,0.163,0.158,0.155,1.0,-0.053],[-0.154,-0.04,0.028,-0.024,0.014,0.325,0.264,0.235,0.217,0.204,0.187,-0.02,-0.014,-0.014,-0.01,-0.007,-0.005,-0.073,-0.059,-0.056,-0.057,-0.055,-0.053,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"y\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"z\":[[1.0,0.024,-0.222,-0.095,0.142,-0.276,-0.3,-0.296,-0.276,-0.252,-0.242,0.272,0.268,0.27,0.279,0.278,0.27,0.195,0.194,0.211,0.223,0.237,0.272,-0.159],[0.024,1.0,0.014,-0.031,-0.095,-0.049,-0.071,-0.067,-0.05,-0.043,-0.031,-0.033,-0.027,-0.021,-0.012,-0.004,-0.005,0.0,-0.028,-0.001,-0.016,-0.005,0.007,-0.03],[-0.222,0.014,1.0,-0.157,0.177,0.103,0.116,0.113,0.108,0.092,0.081,0.017,0.014,0.011,0.002,-0.007,-0.006,-0.031,-0.043,-0.039,-0.046,-0.041,-0.052,0.033],[-0.095,-0.031,-0.157,1.0,-0.436,0.021,0.029,0.033,0.036,0.036,0.037,-0.018,-0.016,-0.016,-0.013,-0.013,-0.012,0.003,0.007,0.009,-0.006,-0.003,-0.003,-0.023],[0.142,-0.095,0.177,-0.436,1.0,-0.047,-0.055,-0.064,-0.057,-0.063,-0.06,0.056,0.054,0.049,0.047,0.042,0.044,0.03,0.028,0.026,0.036,0.026,0.012,0.006],[-0.276,-0.049,0.103,0.021,-0.047,1.0,0.664,0.571,0.539,0.505,0.472,0.199,0.202,0.197,0.192,0.194,0.193,-0.085,-0.075,-0.074,-0.077,-0.064,-0.074,0.326],[-0.3,-0.071,0.116,0.029,-0.055,0.664,1.0,0.776,0.671,0.625,0.58,0.25,0.252,0.245,0.238,0.241,0.241,-0.081,-0.063,-0.055,-0.055,-0.039,-0.045,0.266],[-0.296,-0.067,0.113,0.033,-0.064,0.571,0.776,1.0,0.771,0.681,0.632,0.228,0.254,0.248,0.243,0.243,0.247,0.002,-0.071,-0.057,-0.051,-0.03,-0.04,0.242],[-0.276,-0.05,0.108,0.036,-0.057,0.539,0.671,0.771,1.0,0.812,0.711,0.225,0.248,0.271,0.27,0.267,0.272,-0.013,0.003,-0.062,-0.051,-0.019,-0.028,0.222],[-0.252,-0.043,0.092,0.036,-0.063,0.505,0.625,0.681,0.812,1.0,0.812,0.231,0.25,0.273,0.296,0.291,0.296,-0.005,0.008,0.018,-0.067,-0.013,-0.022,0.206],[-0.242,-0.031,0.081,0.037,-0.06,0.472,0.58,0.632,0.711,0.812,1.0,0.232,0.248,0.269,0.289,0.31,0.312,-0.003,0.01,0.011,0.012,-0.037,-0.022,0.188],[0.272,-0.033,0.017,-0.018,0.056,0.199,0.25,0.228,0.225,0.231,0.232,1.0,0.954,0.924,0.881,0.854,0.834,0.163,0.137,0.156,0.155,0.192,0.229,-0.025],[0.268,-0.027,0.014,-0.016,0.054,0.202,0.252,0.254,0.248,0.25,0.248,0.954,1.0,0.949,0.912,0.878,0.858,0.22,0.143,0.146,0.141,0.183,0.224,-0.017],[0.27,-0.021,0.011,-0.016,0.049,0.197,0.245,0.248,0.271,0.273,0.269,0.924,0.949,1.0,0.94,0.91,0.886,0.209,0.226,0.157,0.141,0.177,0.222,-0.009],[0.279,-0.012,0.002,-0.013,0.047,0.192,0.238,0.243,0.27,0.296,0.289,0.881,0.912,0.94,1.0,0.933,0.905,0.208,0.231,0.242,0.14,0.181,0.213,-0.012],[0.278,-0.004,-0.007,-0.013,0.042,0.194,0.241,0.243,0.267,0.291,0.31,0.854,0.878,0.91,0.933,1.0,0.936,0.205,0.207,0.221,0.255,0.177,0.216,-0.004],[0.27,-0.005,-0.006,-0.012,0.044,0.193,0.241,0.247,0.272,0.296,0.312,0.834,0.858,0.886,0.905,0.936,1.0,0.196,0.182,0.212,0.228,0.286,0.204,-0.002],[0.195,0.0,-0.031,0.003,0.03,-0.085,-0.081,0.002,-0.013,-0.005,-0.003,0.163,0.22,0.209,0.208,0.205,0.196,1.0,0.203,0.201,0.194,0.187,0.208,-0.085],[0.194,-0.028,-0.043,0.007,0.028,-0.075,-0.063,-0.071,0.003,0.008,0.01,0.137,0.143,0.226,0.231,0.207,0.182,0.203,1.0,0.248,0.165,0.154,0.211,-0.075],[0.211,-0.001,-0.039,0.009,0.026,-0.074,-0.055,-0.057,-0.062,0.018,0.011,0.156,0.146,0.157,0.242,0.221,0.212,0.201,0.248,1.0,0.207,0.226,0.231,-0.07],[0.223,-0.016,-0.046,-0.006,0.036,-0.077,-0.055,-0.051,-0.051,-0.067,0.012,0.155,0.141,0.141,0.14,0.255,0.228,0.194,0.165,0.207,1.0,0.237,0.25,-0.071],[0.237,-0.005,-0.041,-0.003,0.026,-0.064,-0.039,-0.03,-0.019,-0.013,-0.037,0.192,0.183,0.177,0.181,0.177,0.286,0.187,0.154,0.226,0.237,1.0,0.288,-0.074],[0.272,0.007,-0.052,-0.003,0.012,-0.074,-0.045,-0.04,-0.028,-0.022,-0.022,0.229,0.224,0.222,0.213,0.216,0.204,0.208,0.211,0.231,0.25,0.288,1.0,-0.081],[-0.159,-0.03,0.033,-0.023,0.006,0.326,0.266,0.242,0.222,0.206,0.188,-0.025,-0.017,-0.009,-0.012,-0.004,-0.002,-0.085,-0.075,-0.07,-0.071,-0.074,-0.081,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.99)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3de00a97-d835-48e5-b455-15301cb82ed5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}